{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda update -c bioconda diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_diamond_command(diamond_command):\n",
    "    try:\n",
    "        result = subprocess.run(diamond_command, capture_output=True, text=True, check=True)\n",
    "        print(\"DIAMOND output:\", result.stdout)\n",
    "        print(\"DIAMOND errors:\", result.stderr)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"DIAMOND failed:\", e.stderr)\n",
    "        raise\n",
    "\n",
    "def generate_feature_matrix(sequences, reference_db_path):\n",
    "    with open(\"temp_sequences.fasta\", \"w\") as f:\n",
    "        for i, seq in enumerate(sequences):\n",
    "            f.write(f\">seq_{i}\\n{seq}\\n\")\n",
    "    \n",
    "    # DIAMOND command setup\n",
    "    diamond_output_file = \"temp_diamond_output.tsv\"\n",
    "    diamond_command = [\n",
    "        \"diamond\", \"blastx\", \n",
    "        \"-q\", \"temp_sequences.fasta\", \n",
    "        \"-d\", reference_db_path, \n",
    "        \"-o\", diamond_output_file, \n",
    "        \"--outfmt\", \"6\",  # Tabular format\n",
    "        \"--evalue\", \"1e-10\",\n",
    "        \"--max-target-seqs\", \"500\",\n",
    "        \"--threads\", \"1\"\n",
    "    ]\n",
    "    \n",
    "    # Run DIAMOND command and capture output\n",
    "    run_diamond_command(diamond_command)\n",
    "    \n",
    "    # Parse DIAMOND output\n",
    "    scores_dict = {}\n",
    "    with open(diamond_output_file) as f:\n",
    "        for line in f:\n",
    "            query_id, subject_id, identity, alignment_length, mismatches, gap_opens, q_start, q_end, s_start, s_end, evalue, bit_score = line.strip().split()\n",
    "            if query_id not in scores_dict:\n",
    "                scores_dict[query_id] = []\n",
    "            scores_dict[query_id].append(float(bit_score))\n",
    "    \n",
    "    # Convert scores_dict to a feature matrix\n",
    "    all_scores = []\n",
    "    for i in range(len(sequences)):\n",
    "        query_id = f\"seq_{i}\"\n",
    "        scores = scores_dict.get(query_id, [])\n",
    "        all_scores.append(scores)\n",
    "    \n",
    "    # Pad with zeros and normalize\n",
    "    max_hits = max(len(scores) for scores in all_scores)\n",
    "    feature_matrix = np.array([np.pad(scores, (0, max_hits - len(scores)), 'constant') for scores in all_scores])\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_features = scaler.fit_transform(feature_matrix)\n",
    "    \n",
    "    # Clean up temporary files\n",
    "    subprocess.run([\"rm\", \"temp_sequences.fasta\", \"temp_diamond_output.tsv\"])\n",
    "    \n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARGModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=30):\n",
    "        super(DeepARGModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 2000)\n",
    "        self.fc2 = nn.Linear(2000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 500)\n",
    "        self.fc4 = nn.Linear(500, 100)\n",
    "        self.output = nn.Linear(100, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_dataframe(fasta_file):\n",
    "    records = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        records.append({\"id\": record.id.split('|')[0]\n",
    "                        , \"db\": record.id.split('|')[2]\n",
    "                        , \"type\": record.id.split('|')[3]\n",
    "                        , \"sequence\": str(record.seq)})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "data = fasta_to_dataframe(\"../data/database/v1/features.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['diamond', 'makedb', '--in', 'card_ardb_reference.fasta', '-d', 'card_ardb_db'], returncode=-9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniprot_data = data[data['db'] == 'UNIPROT']\n",
    "card_ardb_data = data[data['db'].isin(['CARD', 'ARDB'])]\n",
    "\n",
    "train_df, val_df = train_test_split(uniprot_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# Write CARD and ARDB sequences to a FASTA file to create a DIAMOND database\n",
    "with open(\"card_ardb_reference.fasta\", \"w\") as f:\n",
    "    for i, row in card_ardb_data.iterrows():\n",
    "        f.write(f\">{row['type']}_{i}\\n{row['sequence']}\\n\")\n",
    "\n",
    "# Create DIAMOND database for CARD and ARDB\n",
    "subprocess.run([\"diamond\", \"makedb\", \"--in\", \"card_ardb_reference.fasta\", \"-d\", \"card_ardb_db\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAMOND failed: \n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['diamond', 'blastx', '-q', 'temp_sequences.fasta', '-d', 'card_ardb_db', '-o', 'temp_diamond_output.tsv', '--outfmt', '6', '--evalue', '1e-10', '--max-target-seqs', '1000', '--threads', '1']' died with <Signals.SIGKILL: 9>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m reference_db_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcard_ardb_db\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# DIAMOND database path\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m generate_feature_matrix(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m], reference_db_path)\n\u001b[1;32m      3\u001b[0m X_val \u001b[38;5;241m=\u001b[39m generate_feature_matrix(val_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m], reference_db_path)\n",
      "Cell \u001b[0;32mIn[35], line 29\u001b[0m, in \u001b[0;36mgenerate_feature_matrix\u001b[0;34m(sequences, reference_db_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m diamond_command \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiamond\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblastx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-q\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_sequences.fasta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m ]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Run DIAMOND command and capture output\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m run_diamond_command(diamond_command)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Parse DIAMOND output\u001b[39;00m\n\u001b[1;32m     32\u001b[0m scores_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36mrun_diamond_command\u001b[0;34m(diamond_command)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_diamond_command\u001b[39m(diamond_command):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         result \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(diamond_command, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIAMOND output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIAMOND errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['diamond', 'blastx', '-q', 'temp_sequences.fasta', '-d', 'card_ardb_db', '-o', 'temp_diamond_output.tsv', '--outfmt', '6', '--evalue', '1e-10', '--max-target-seqs', '1000', '--threads', '1']' died with <Signals.SIGKILL: 9>."
     ]
    }
   ],
   "source": [
    "reference_db_path = \"card_ardb_db\"  # DIAMOND database path\n",
    "X_train = generate_feature_matrix(train_df['sequence'], reference_db_path)\n",
    "X_val = generate_feature_matrix(val_df['sequence'], reference_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAMOND failed: \n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['diamond', 'blastx', '-q', 'temp_sequences.fasta', '-d', 'card_ardb_db', '-o', 'temp_diamond_output.tsv', '--outfmt', '6', '--evalue', '1e-10', '--max-target-seqs', '500', '--threads', '1']' died with <Signals.SIGKILL: 9>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sampled_sequences \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m X_train_sample \u001b[38;5;241m=\u001b[39m generate_feature_matrix(sampled_sequences, reference_db_path)\n",
      "Cell \u001b[0;32mIn[42], line 29\u001b[0m, in \u001b[0;36mgenerate_feature_matrix\u001b[0;34m(sequences, reference_db_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m diamond_command \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiamond\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblastx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-q\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_sequences.fasta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m ]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Run DIAMOND command and capture output\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m run_diamond_command(diamond_command)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Parse DIAMOND output\u001b[39;00m\n\u001b[1;32m     32\u001b[0m scores_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m, in \u001b[0;36mrun_diamond_command\u001b[0;34m(diamond_command)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_diamond_command\u001b[39m(diamond_command):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         result \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(diamond_command, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIAMOND output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIAMOND errors:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['diamond', 'blastx', '-q', 'temp_sequences.fasta', '-d', 'card_ardb_db', '-o', 'temp_diamond_output.tsv', '--outfmt', '6', '--evalue', '1e-10', '--max-target-seqs', '500', '--threads', '1']' died with <Signals.SIGKILL: 9>."
     ]
    }
   ],
   "source": [
    "sampled_sequences = train_df['sequence'].values[:10]\n",
    "X_train_sample = generate_feature_matrix(sampled_sequences, reference_db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "! diamond --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {label: idx for idx, label in enumerate(train_df['label'].unique())}\n",
    "y_train = train_df['label'].map(label_mapping).values\n",
    "y_val = val_df['label'].map(label_mapping).values\n",
    "\n",
    "# Prepare Torch datasets and dataloaders\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "model = DeepARGModel(input_dim=input_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            outputs = model(X_val_batch)\n",
    "            loss = criterion(outputs, y_val_batch)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_val_batch.size(0)\n",
    "            correct += (predicted == y_val_batch).sum().item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total:.2f}%\")y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
