{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc43ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcca8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lr_dna_feature_matrix.pkl', 'rb') as handle:\n",
    "    feature_matrix = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e06d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_data = pd.read_csv('all_df_v2.csv')\n",
    "uniprot_data = dna_data[dna_data['db'] == 'UNIPROT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "896abd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_invalid_dna_bases(sequence):\n",
    "    valid_bases = {'A', 'T', 'C', 'G'}\n",
    "    return any(base not in valid_bases for base in sequence.upper())\n",
    "\n",
    "uniprot_data = uniprot_data[~uniprot_data['dna_seq'].apply(contains_invalid_dna_bases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc5fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, uniprot_data.type, test_size=0.3, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa5d17da",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train) \n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dca6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "575992ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cf634ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARGMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DeepARGMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 2000)\n",
    "        self.fc2 = nn.Linear(2000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 500)\n",
    "        self.fc4 = nn.Linear(500, 100)\n",
    "        self.output = nn.Linear(100, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f71bd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "149b022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "num_classes = uniprot_data['type'].nunique()\n",
    "\n",
    "model = DeepARGMLP(input_dim=input_dim, output_dim=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea80ef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5166384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold 1\n",
      "Fold 1 Epoch 1/100, Loss: 2.7001, Val Loss: 2.6927, F1 Score: 0.2063\n",
      "Fold 1 Epoch 2/100, Loss: 2.6820, Val Loss: 2.6677, F1 Score: 0.2063\n",
      "Fold 1 Epoch 3/100, Loss: 2.6334, Val Loss: 2.5593, F1 Score: 0.2063\n",
      "Fold 1 Epoch 4/100, Loss: 2.4204, Val Loss: 2.3672, F1 Score: 0.2063\n",
      "Fold 1 Epoch 5/100, Loss: 2.2953, Val Loss: 2.1834, F1 Score: 0.5636\n",
      "Fold 1 Epoch 6/100, Loss: 2.1537, Val Loss: 2.1590, F1 Score: 0.5636\n",
      "Fold 1 Epoch 7/100, Loss: 2.1455, Val Loss: 2.1561, F1 Score: 0.5633\n",
      "Fold 1 Epoch 8/100, Loss: 2.1416, Val Loss: 2.1529, F1 Score: 0.5566\n",
      "Fold 1 Epoch 9/100, Loss: 2.1403, Val Loss: 2.1517, F1 Score: 0.5562\n",
      "Fold 1 Epoch 10/100, Loss: 2.1376, Val Loss: 2.1510, F1 Score: 0.5546\n",
      "Fold 1 Epoch 11/100, Loss: 2.1378, Val Loss: 2.1503, F1 Score: 0.5512\n",
      "Fold 1 Epoch 12/100, Loss: 2.1357, Val Loss: 2.1499, F1 Score: 0.5524\n",
      "Fold 1 Epoch 13/100, Loss: 2.1371, Val Loss: 2.1496, F1 Score: 0.5592\n",
      "Fold 1 Epoch 14/100, Loss: 2.1349, Val Loss: 2.1488, F1 Score: 0.5508\n",
      "Fold 1 Epoch 15/100, Loss: 2.1333, Val Loss: 2.1478, F1 Score: 0.5564\n",
      "Fold 1 Epoch 16/100, Loss: 2.1327, Val Loss: 2.1469, F1 Score: 0.5569\n",
      "Fold 1 Epoch 17/100, Loss: 2.1321, Val Loss: 2.1454, F1 Score: 0.5529\n",
      "Fold 1 Epoch 18/100, Loss: 2.1302, Val Loss: 2.1438, F1 Score: 0.5508\n",
      "Fold 1 Epoch 19/100, Loss: 2.1298, Val Loss: 2.1422, F1 Score: 0.5496\n",
      "Fold 1 Epoch 20/100, Loss: 2.1277, Val Loss: 2.1401, F1 Score: 0.5539\n",
      "Fold 1 Epoch 21/100, Loss: 2.1241, Val Loss: 2.1378, F1 Score: 0.5532\n",
      "Fold 1 Epoch 22/100, Loss: 2.1215, Val Loss: 2.1351, F1 Score: 0.5548\n",
      "Fold 1 Epoch 23/100, Loss: 2.1195, Val Loss: 2.1315, F1 Score: 0.5554\n",
      "Fold 1 Epoch 24/100, Loss: 2.1140, Val Loss: 2.1268, F1 Score: 0.5569\n",
      "Fold 1 Epoch 25/100, Loss: 2.1112, Val Loss: 2.1207, F1 Score: 0.6414\n",
      "Fold 1 Epoch 26/100, Loss: 2.1040, Val Loss: 2.1120, F1 Score: 0.6818\n",
      "Fold 1 Epoch 27/100, Loss: 2.0965, Val Loss: 2.1004, F1 Score: 0.6809\n",
      "Fold 1 Epoch 28/100, Loss: 2.0888, Val Loss: 2.0912, F1 Score: 0.6809\n",
      "Fold 1 Epoch 29/100, Loss: 2.0803, Val Loss: 2.0817, F1 Score: 0.6809\n",
      "Fold 1 Epoch 30/100, Loss: 2.0708, Val Loss: 2.0638, F1 Score: 0.7478\n",
      "Fold 1 Epoch 31/100, Loss: 2.0543, Val Loss: 2.0447, F1 Score: 0.7487\n",
      "Fold 1 Epoch 32/100, Loss: 2.0406, Val Loss: 2.0375, F1 Score: 0.7491\n",
      "Fold 1 Epoch 33/100, Loss: 2.0338, Val Loss: 2.0345, F1 Score: 0.7433\n",
      "Fold 1 Epoch 34/100, Loss: 2.0284, Val Loss: 2.0329, F1 Score: 0.7442\n",
      "Fold 1 Epoch 35/100, Loss: 2.0262, Val Loss: 2.0319, F1 Score: 0.7438\n",
      "Fold 1 Epoch 36/100, Loss: 2.0233, Val Loss: 2.0314, F1 Score: 0.7439\n",
      "Fold 1 Epoch 37/100, Loss: 2.0219, Val Loss: 2.0310, F1 Score: 0.7431\n",
      "Fold 1 Epoch 38/100, Loss: 2.0209, Val Loss: 2.0306, F1 Score: 0.7433\n",
      "Fold 1 Epoch 39/100, Loss: 2.0184, Val Loss: 2.0302, F1 Score: 0.7434\n",
      "Fold 1 Epoch 40/100, Loss: 2.0185, Val Loss: 2.0297, F1 Score: 0.7439\n",
      "Fold 1 Epoch 41/100, Loss: 2.0177, Val Loss: 2.0292, F1 Score: 0.7437\n",
      "Fold 1 Epoch 42/100, Loss: 2.0172, Val Loss: 2.0286, F1 Score: 0.7465\n",
      "Fold 1 Epoch 43/100, Loss: 2.0158, Val Loss: 2.0279, F1 Score: 0.7434\n",
      "Fold 1 Epoch 44/100, Loss: 2.0143, Val Loss: 2.0270, F1 Score: 0.7465\n",
      "Fold 1 Epoch 45/100, Loss: 2.0136, Val Loss: 2.0256, F1 Score: 0.7450\n",
      "Fold 1 Epoch 46/100, Loss: 2.0140, Val Loss: 2.0243, F1 Score: 0.7477\n",
      "Fold 1 Epoch 47/100, Loss: 2.0108, Val Loss: 2.0185, F1 Score: 0.7487\n",
      "Fold 1 Epoch 48/100, Loss: 2.0069, Val Loss: 2.0148, F1 Score: 0.7865\n",
      "Fold 1 Epoch 49/100, Loss: 2.0048, Val Loss: 2.0107, F1 Score: 0.8036\n",
      "Fold 1 Epoch 50/100, Loss: 2.0027, Val Loss: 2.0069, F1 Score: 0.8084\n",
      "Fold 1 Epoch 51/100, Loss: 2.0000, Val Loss: 1.9997, F1 Score: 0.8107\n",
      "Fold 1 Epoch 52/100, Loss: 1.9962, Val Loss: 1.9954, F1 Score: 0.8107\n",
      "Fold 1 Epoch 53/100, Loss: 1.9936, Val Loss: 1.9914, F1 Score: 0.8107\n",
      "Fold 1 Epoch 54/100, Loss: 1.9912, Val Loss: 1.9872, F1 Score: 0.8109\n",
      "Fold 1 Epoch 55/100, Loss: 1.9876, Val Loss: 1.9848, F1 Score: 0.8109\n",
      "Fold 1 Epoch 56/100, Loss: 1.9841, Val Loss: 1.9835, F1 Score: 0.8109\n",
      "Fold 1 Epoch 57/100, Loss: 1.9812, Val Loss: 1.9820, F1 Score: 0.8109\n",
      "Fold 1 Epoch 58/100, Loss: 1.9807, Val Loss: 1.9809, F1 Score: 0.8109\n",
      "Fold 1 Epoch 59/100, Loss: 1.9770, Val Loss: 1.9804, F1 Score: 0.8107\n",
      "Fold 1 Epoch 60/100, Loss: 1.9800, Val Loss: 1.9789, F1 Score: 0.8107\n",
      "Fold 1 Epoch 61/100, Loss: 1.9748, Val Loss: 1.9779, F1 Score: 0.8107\n",
      "Fold 1 Epoch 62/100, Loss: 1.9727, Val Loss: 1.9771, F1 Score: 0.8109\n",
      "Fold 1 Epoch 63/100, Loss: 1.9717, Val Loss: 1.9763, F1 Score: 0.8107\n",
      "Fold 1 Epoch 64/100, Loss: 1.9731, Val Loss: 1.9754, F1 Score: 0.8105\n",
      "Fold 1 Epoch 65/100, Loss: 1.9726, Val Loss: 1.9746, F1 Score: 0.8107\n",
      "Fold 1 Epoch 66/100, Loss: 1.9707, Val Loss: 1.9735, F1 Score: 0.8109\n",
      "Fold 1 Epoch 67/100, Loss: 1.9702, Val Loss: 1.9720, F1 Score: 0.8164\n",
      "Fold 1 Epoch 68/100, Loss: 1.9672, Val Loss: 1.9710, F1 Score: 0.8498\n",
      "Fold 1 Epoch 69/100, Loss: 1.9647, Val Loss: 1.9687, F1 Score: 0.8494\n",
      "Fold 1 Epoch 70/100, Loss: 1.9653, Val Loss: 1.9673, F1 Score: 0.8494\n",
      "Fold 1 Epoch 71/100, Loss: 1.9622, Val Loss: 1.9651, F1 Score: 0.8509\n",
      "Fold 1 Epoch 72/100, Loss: 1.9602, Val Loss: 1.9635, F1 Score: 0.8509\n",
      "Fold 1 Epoch 73/100, Loss: 1.9584, Val Loss: 1.9616, F1 Score: 0.8510\n",
      "Fold 1 Epoch 74/100, Loss: 1.9553, Val Loss: 1.9597, F1 Score: 0.8510\n",
      "Fold 1 Epoch 75/100, Loss: 1.9544, Val Loss: 1.9580, F1 Score: 0.8510\n",
      "Fold 1 Epoch 76/100, Loss: 1.9518, Val Loss: 1.9567, F1 Score: 0.8509\n",
      "Fold 1 Epoch 77/100, Loss: 1.9504, Val Loss: 1.9556, F1 Score: 0.8510\n",
      "Fold 1 Epoch 78/100, Loss: 1.9502, Val Loss: 1.9551, F1 Score: 0.8510\n",
      "Fold 1 Epoch 79/100, Loss: 1.9472, Val Loss: 1.9549, F1 Score: 0.8510\n",
      "Fold 1 Epoch 80/100, Loss: 1.9474, Val Loss: 1.9545, F1 Score: 0.8509\n",
      "Fold 1 Epoch 81/100, Loss: 1.9475, Val Loss: 1.9542, F1 Score: 0.8509\n",
      "Fold 1 Epoch 82/100, Loss: 1.9470, Val Loss: 1.9539, F1 Score: 0.8509\n",
      "Fold 1 Epoch 83/100, Loss: 1.9469, Val Loss: 1.9540, F1 Score: 0.8509\n",
      "Fold 1 Epoch 84/100, Loss: 1.9453, Val Loss: 1.9538, F1 Score: 0.8509\n",
      "Fold 1 Epoch 85/100, Loss: 1.9456, Val Loss: 1.9536, F1 Score: 0.8509\n",
      "Fold 1 Epoch 86/100, Loss: 1.9470, Val Loss: 1.9535, F1 Score: 0.8509\n",
      "Fold 1 Epoch 87/100, Loss: 1.9467, Val Loss: 1.9534, F1 Score: 0.8509\n",
      "Fold 1 Epoch 88/100, Loss: 1.9457, Val Loss: 1.9532, F1 Score: 0.8509\n",
      "Fold 1 Epoch 89/100, Loss: 1.9453, Val Loss: 1.9530, F1 Score: 0.8467\n",
      "Fold 1 Epoch 90/100, Loss: 1.9453, Val Loss: 1.9530, F1 Score: 0.8467\n",
      "Fold 1 Epoch 91/100, Loss: 1.9439, Val Loss: 1.9530, F1 Score: 0.8468\n",
      "Fold 1 Epoch 92/100, Loss: 1.9448, Val Loss: 1.9530, F1 Score: 0.8468\n",
      "Fold 1 Epoch 93/100, Loss: 1.9432, Val Loss: 1.9531, F1 Score: 0.8467\n",
      "Fold 1 Epoch 94/100, Loss: 1.9444, Val Loss: 1.9528, F1 Score: 0.8468\n",
      "Fold 1 Epoch 95/100, Loss: 1.9432, Val Loss: 1.9528, F1 Score: 0.8467\n",
      "Fold 1 Epoch 96/100, Loss: 1.9440, Val Loss: 1.9526, F1 Score: 0.8503\n",
      "Fold 1 Epoch 97/100, Loss: 1.9435, Val Loss: 1.9528, F1 Score: 0.8470\n",
      "Fold 1 Epoch 98/100, Loss: 1.9431, Val Loss: 1.9527, F1 Score: 0.8467\n",
      "Fold 1 Epoch 99/100, Loss: 1.9434, Val Loss: 1.9523, F1 Score: 0.8467\n",
      "Fold 1 Epoch 100/100, Loss: 1.9426, Val Loss: 1.9524, F1 Score: 0.8467\n",
      "Starting Fold 2\n",
      "Fold 2 Epoch 1/100, Loss: 2.7053, Val Loss: 2.6986, F1 Score: 0.2063\n",
      "Fold 2 Epoch 2/100, Loss: 2.6888, Val Loss: 2.6762, F1 Score: 0.2063\n",
      "Fold 2 Epoch 3/100, Loss: 2.6482, Val Loss: 2.5961, F1 Score: 0.2063\n",
      "Fold 2 Epoch 4/100, Loss: 2.4530, Val Loss: 2.3152, F1 Score: 0.3694\n",
      "Fold 2 Epoch 5/100, Loss: 2.1997, Val Loss: 2.1361, F1 Score: 0.5805\n",
      "Fold 2 Epoch 6/100, Loss: 2.1447, Val Loss: 2.1321, F1 Score: 0.5827\n",
      "Fold 2 Epoch 7/100, Loss: 2.1419, Val Loss: 2.1308, F1 Score: 0.5713\n",
      "Fold 2 Epoch 8/100, Loss: 2.1394, Val Loss: 2.1300, F1 Score: 0.5699\n",
      "Fold 2 Epoch 9/100, Loss: 2.1395, Val Loss: 2.1287, F1 Score: 0.5732\n",
      "Fold 2 Epoch 10/100, Loss: 2.1394, Val Loss: 2.1281, F1 Score: 0.5661\n",
      "Fold 2 Epoch 11/100, Loss: 2.1358, Val Loss: 2.1270, F1 Score: 0.5671\n",
      "Fold 2 Epoch 12/100, Loss: 2.1345, Val Loss: 2.1257, F1 Score: 0.5671\n",
      "Fold 2 Epoch 13/100, Loss: 2.1337, Val Loss: 2.1246, F1 Score: 0.5661\n",
      "Fold 2 Epoch 14/100, Loss: 2.1337, Val Loss: 2.1233, F1 Score: 0.5640\n",
      "Fold 2 Epoch 15/100, Loss: 2.1307, Val Loss: 2.1217, F1 Score: 0.5636\n",
      "Fold 2 Epoch 16/100, Loss: 2.1308, Val Loss: 2.1200, F1 Score: 0.5637\n",
      "Fold 2 Epoch 17/100, Loss: 2.1278, Val Loss: 2.1183, F1 Score: 0.5637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Epoch 18/100, Loss: 2.1276, Val Loss: 2.1159, F1 Score: 0.5626\n",
      "Fold 2 Epoch 19/100, Loss: 2.1229, Val Loss: 2.1132, F1 Score: 0.5631\n",
      "Fold 2 Epoch 20/100, Loss: 2.1187, Val Loss: 2.1073, F1 Score: 0.6366\n",
      "Fold 2 Epoch 21/100, Loss: 2.1110, Val Loss: 2.0918, F1 Score: 0.6824\n",
      "Fold 2 Epoch 22/100, Loss: 2.0956, Val Loss: 2.0768, F1 Score: 0.6853\n",
      "Fold 2 Epoch 23/100, Loss: 2.0853, Val Loss: 2.0718, F1 Score: 0.6824\n",
      "Fold 2 Epoch 24/100, Loss: 2.0790, Val Loss: 2.0682, F1 Score: 0.6824\n",
      "Fold 2 Epoch 25/100, Loss: 2.0735, Val Loss: 2.0642, F1 Score: 0.6824\n",
      "Fold 2 Epoch 26/100, Loss: 2.0690, Val Loss: 2.0599, F1 Score: 0.7186\n",
      "Fold 2 Epoch 27/100, Loss: 2.0635, Val Loss: 2.0522, F1 Score: 0.7586\n",
      "Fold 2 Epoch 28/100, Loss: 2.0550, Val Loss: 2.0443, F1 Score: 0.7587\n",
      "Fold 2 Epoch 29/100, Loss: 2.0499, Val Loss: 2.0354, F1 Score: 0.7606\n",
      "Fold 2 Epoch 30/100, Loss: 2.0396, Val Loss: 2.0276, F1 Score: 0.7611\n",
      "Fold 2 Epoch 31/100, Loss: 2.0348, Val Loss: 2.0231, F1 Score: 0.7577\n",
      "Fold 2 Epoch 32/100, Loss: 2.0317, Val Loss: 2.0205, F1 Score: 0.7512\n",
      "Fold 2 Epoch 33/100, Loss: 2.0271, Val Loss: 2.0178, F1 Score: 0.7501\n",
      "Fold 2 Epoch 34/100, Loss: 2.0254, Val Loss: 2.0166, F1 Score: 0.7510\n",
      "Fold 2 Epoch 35/100, Loss: 2.0258, Val Loss: 2.0159, F1 Score: 0.7515\n",
      "Fold 2 Epoch 36/100, Loss: 2.0226, Val Loss: 2.0153, F1 Score: 0.7517\n",
      "Fold 2 Epoch 37/100, Loss: 2.0207, Val Loss: 2.0150, F1 Score: 0.7510\n",
      "Fold 2 Epoch 38/100, Loss: 2.0200, Val Loss: 2.0145, F1 Score: 0.7515\n",
      "Fold 2 Epoch 39/100, Loss: 2.0200, Val Loss: 2.0138, F1 Score: 0.7511\n",
      "Fold 2 Epoch 40/100, Loss: 2.0196, Val Loss: 2.0137, F1 Score: 0.7513\n",
      "Fold 2 Epoch 41/100, Loss: 2.0183, Val Loss: 2.0132, F1 Score: 0.7500\n",
      "Fold 2 Epoch 42/100, Loss: 2.0193, Val Loss: 2.0127, F1 Score: 0.7500\n",
      "Fold 2 Epoch 43/100, Loss: 2.0179, Val Loss: 2.0116, F1 Score: 0.7521\n",
      "Fold 2 Epoch 44/100, Loss: 2.0174, Val Loss: 2.0100, F1 Score: 0.7547\n",
      "Fold 2 Epoch 45/100, Loss: 2.0137, Val Loss: 2.0062, F1 Score: 0.7539\n",
      "Fold 2 Epoch 46/100, Loss: 2.0112, Val Loss: 2.0025, F1 Score: 0.7542\n",
      "Fold 2 Epoch 47/100, Loss: 2.0082, Val Loss: 1.9988, F1 Score: 0.8064\n",
      "Fold 2 Epoch 48/100, Loss: 2.0062, Val Loss: 1.9949, F1 Score: 0.8120\n",
      "Fold 2 Epoch 49/100, Loss: 2.0021, Val Loss: 1.9904, F1 Score: 0.8216\n",
      "Fold 2 Epoch 50/100, Loss: 2.0005, Val Loss: 1.9849, F1 Score: 0.8228\n",
      "Fold 2 Epoch 51/100, Loss: 1.9947, Val Loss: 1.9803, F1 Score: 0.8231\n",
      "Fold 2 Epoch 52/100, Loss: 1.9924, Val Loss: 1.9761, F1 Score: 0.8242\n",
      "Fold 2 Epoch 53/100, Loss: 1.9896, Val Loss: 1.9728, F1 Score: 0.8229\n",
      "Fold 2 Epoch 54/100, Loss: 1.9875, Val Loss: 1.9689, F1 Score: 0.8242\n",
      "Fold 2 Epoch 55/100, Loss: 1.9867, Val Loss: 1.9672, F1 Score: 0.8229\n",
      "Fold 2 Epoch 56/100, Loss: 1.9843, Val Loss: 1.9647, F1 Score: 0.8242\n",
      "Fold 2 Epoch 57/100, Loss: 1.9827, Val Loss: 1.9631, F1 Score: 0.8242\n",
      "Fold 2 Epoch 58/100, Loss: 1.9803, Val Loss: 1.9622, F1 Score: 0.8229\n",
      "Fold 2 Epoch 59/100, Loss: 1.9804, Val Loss: 1.9607, F1 Score: 0.8242\n",
      "Fold 2 Epoch 60/100, Loss: 1.9774, Val Loss: 1.9595, F1 Score: 0.8226\n",
      "Fold 2 Epoch 61/100, Loss: 1.9773, Val Loss: 1.9579, F1 Score: 0.8242\n",
      "Fold 2 Epoch 62/100, Loss: 1.9755, Val Loss: 1.9552, F1 Score: 0.8239\n",
      "Fold 2 Epoch 63/100, Loss: 1.9747, Val Loss: 1.9543, F1 Score: 0.8226\n",
      "Fold 2 Epoch 64/100, Loss: 1.9719, Val Loss: 1.9513, F1 Score: 0.8672\n",
      "Fold 2 Epoch 65/100, Loss: 1.9678, Val Loss: 1.9487, F1 Score: 0.8672\n",
      "Fold 2 Epoch 66/100, Loss: 1.9665, Val Loss: 1.9464, F1 Score: 0.8672\n",
      "Fold 2 Epoch 67/100, Loss: 1.9621, Val Loss: 1.9417, F1 Score: 0.8685\n",
      "Fold 2 Epoch 68/100, Loss: 1.9615, Val Loss: 1.9392, F1 Score: 0.8685\n",
      "Fold 2 Epoch 69/100, Loss: 1.9599, Val Loss: 1.9379, F1 Score: 0.8672\n",
      "Fold 2 Epoch 70/100, Loss: 1.9569, Val Loss: 1.9361, F1 Score: 0.8684\n",
      "Fold 2 Epoch 71/100, Loss: 1.9541, Val Loss: 1.9367, F1 Score: 0.8684\n",
      "Fold 2 Epoch 72/100, Loss: 1.9549, Val Loss: 1.9328, F1 Score: 0.8710\n",
      "Fold 2 Epoch 73/100, Loss: 1.9534, Val Loss: 1.9329, F1 Score: 0.8685\n",
      "Fold 2 Epoch 74/100, Loss: 1.9505, Val Loss: 1.9303, F1 Score: 0.8711\n",
      "Fold 2 Epoch 75/100, Loss: 1.9503, Val Loss: 1.9308, F1 Score: 0.8711\n",
      "Fold 2 Epoch 76/100, Loss: 1.9484, Val Loss: 1.9341, F1 Score: 0.8684\n",
      "Fold 2 Epoch 77/100, Loss: 1.9485, Val Loss: 1.9302, F1 Score: 0.8710\n",
      "Fold 2 Epoch 78/100, Loss: 1.9477, Val Loss: 1.9302, F1 Score: 0.8711\n",
      "Fold 2 Epoch 79/100, Loss: 1.9464, Val Loss: 1.9316, F1 Score: 0.8698\n",
      "Fold 2 Epoch 80/100, Loss: 1.9468, Val Loss: 1.9292, F1 Score: 0.8711\n",
      "Fold 2 Epoch 81/100, Loss: 1.9465, Val Loss: 1.9305, F1 Score: 0.8699\n",
      "Fold 2 Epoch 82/100, Loss: 1.9475, Val Loss: 1.9295, F1 Score: 0.8711\n",
      "Fold 2 Epoch 83/100, Loss: 1.9480, Val Loss: 1.9293, F1 Score: 0.8711\n",
      "Fold 2 Epoch 84/100, Loss: 1.9493, Val Loss: 1.9290, F1 Score: 0.8711\n",
      "Fold 2 Epoch 85/100, Loss: 1.9460, Val Loss: 1.9293, F1 Score: 0.8711\n",
      "Fold 2 Epoch 86/100, Loss: 1.9456, Val Loss: 1.9300, F1 Score: 0.8697\n",
      "Fold 2 Epoch 87/100, Loss: 1.9463, Val Loss: 1.9290, F1 Score: 0.8710\n",
      "Fold 2 Epoch 88/100, Loss: 1.9468, Val Loss: 1.9291, F1 Score: 0.8710\n",
      "Fold 2 Epoch 89/100, Loss: 1.9465, Val Loss: 1.9284, F1 Score: 0.8711\n",
      "Fold 2 Epoch 90/100, Loss: 1.9475, Val Loss: 1.9294, F1 Score: 0.8710\n",
      "Fold 2 Epoch 91/100, Loss: 1.9466, Val Loss: 1.9289, F1 Score: 0.8710\n",
      "Fold 2 Epoch 92/100, Loss: 1.9451, Val Loss: 1.9290, F1 Score: 0.8710\n",
      "Fold 2 Epoch 93/100, Loss: 1.9454, Val Loss: 1.9294, F1 Score: 0.8711\n",
      "Fold 2 Epoch 94/100, Loss: 1.9456, Val Loss: 1.9288, F1 Score: 0.8711\n",
      "Fold 2 Epoch 95/100, Loss: 1.9454, Val Loss: 1.9292, F1 Score: 0.8711\n",
      "Fold 2 Epoch 96/100, Loss: 1.9459, Val Loss: 1.9304, F1 Score: 0.8699\n",
      "Fold 2 Epoch 97/100, Loss: 1.9456, Val Loss: 1.9295, F1 Score: 0.8710\n",
      "Fold 2 Epoch 98/100, Loss: 1.9455, Val Loss: 1.9289, F1 Score: 0.8710\n",
      "Fold 2 Epoch 99/100, Loss: 1.9454, Val Loss: 1.9292, F1 Score: 0.8711\n",
      "Fold 2 Epoch 100/100, Loss: 1.9456, Val Loss: 1.9290, F1 Score: 0.8709\n",
      "Starting Fold 3\n",
      "Fold 3 Epoch 1/100, Loss: 2.7036, Val Loss: 2.6960, F1 Score: 0.1639\n",
      "Fold 3 Epoch 2/100, Loss: 2.6860, Val Loss: 2.6722, F1 Score: 0.1639\n",
      "Fold 3 Epoch 3/100, Loss: 2.6455, Val Loss: 2.5970, F1 Score: 0.2076\n",
      "Fold 3 Epoch 4/100, Loss: 2.4701, Val Loss: 2.3353, F1 Score: 0.2076\n",
      "Fold 3 Epoch 5/100, Loss: 2.2298, Val Loss: 2.1387, F1 Score: 0.5768\n",
      "Fold 3 Epoch 6/100, Loss: 2.1471, Val Loss: 2.1336, F1 Score: 0.5780\n",
      "Fold 3 Epoch 7/100, Loss: 2.1423, Val Loss: 2.1324, F1 Score: 0.5633\n",
      "Fold 3 Epoch 8/100, Loss: 2.1398, Val Loss: 2.1319, F1 Score: 0.5629\n",
      "Fold 3 Epoch 9/100, Loss: 2.1394, Val Loss: 2.1313, F1 Score: 0.5618\n",
      "Fold 3 Epoch 10/100, Loss: 2.1403, Val Loss: 2.1309, F1 Score: 0.5600\n",
      "Fold 3 Epoch 11/100, Loss: 2.1369, Val Loss: 2.1307, F1 Score: 0.5581\n",
      "Fold 3 Epoch 12/100, Loss: 2.1376, Val Loss: 2.1296, F1 Score: 0.5615\n",
      "Fold 3 Epoch 13/100, Loss: 2.1378, Val Loss: 2.1295, F1 Score: 0.5581\n",
      "Fold 3 Epoch 14/100, Loss: 2.1366, Val Loss: 2.1285, F1 Score: 0.5581\n",
      "Fold 3 Epoch 15/100, Loss: 2.1345, Val Loss: 2.1272, F1 Score: 0.5581\n",
      "Fold 3 Epoch 16/100, Loss: 2.1345, Val Loss: 2.1258, F1 Score: 0.5584\n",
      "Fold 3 Epoch 17/100, Loss: 2.1347, Val Loss: 2.1241, F1 Score: 0.5585\n",
      "Fold 3 Epoch 18/100, Loss: 2.1317, Val Loss: 2.1221, F1 Score: 0.5584\n",
      "Fold 3 Epoch 19/100, Loss: 2.1297, Val Loss: 2.1199, F1 Score: 0.5594\n",
      "Fold 3 Epoch 20/100, Loss: 2.1279, Val Loss: 2.1176, F1 Score: 0.5586\n",
      "Fold 3 Epoch 21/100, Loss: 2.1255, Val Loss: 2.1148, F1 Score: 0.5619\n",
      "Fold 3 Epoch 22/100, Loss: 2.1243, Val Loss: 2.1118, F1 Score: 0.5631\n",
      "Fold 3 Epoch 23/100, Loss: 2.1196, Val Loss: 2.1069, F1 Score: 0.5662\n",
      "Fold 3 Epoch 24/100, Loss: 2.1139, Val Loss: 2.0987, F1 Score: 0.6853\n",
      "Fold 3 Epoch 25/100, Loss: 2.1052, Val Loss: 2.0816, F1 Score: 0.6925\n",
      "Fold 3 Epoch 26/100, Loss: 2.0944, Val Loss: 2.0714, F1 Score: 0.6925\n",
      "Fold 3 Epoch 27/100, Loss: 2.0901, Val Loss: 2.0666, F1 Score: 0.6910\n",
      "Fold 3 Epoch 28/100, Loss: 2.0827, Val Loss: 2.0635, F1 Score: 0.6862\n",
      "Fold 3 Epoch 29/100, Loss: 2.0795, Val Loss: 2.0607, F1 Score: 0.6824\n",
      "Fold 3 Epoch 30/100, Loss: 2.0765, Val Loss: 2.0575, F1 Score: 0.6834\n",
      "Fold 3 Epoch 31/100, Loss: 2.0726, Val Loss: 2.0535, F1 Score: 0.6781\n",
      "Fold 3 Epoch 32/100, Loss: 2.0680, Val Loss: 2.0472, F1 Score: 0.7509\n",
      "Fold 3 Epoch 33/100, Loss: 2.0634, Val Loss: 2.0404, F1 Score: 0.7479\n",
      "Fold 3 Epoch 34/100, Loss: 2.0552, Val Loss: 2.0316, F1 Score: 0.7449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Epoch 35/100, Loss: 2.0484, Val Loss: 2.0208, F1 Score: 0.7487\n",
      "Fold 3 Epoch 36/100, Loss: 2.0389, Val Loss: 2.0135, F1 Score: 0.7490\n",
      "Fold 3 Epoch 37/100, Loss: 2.0330, Val Loss: 2.0092, F1 Score: 0.7502\n",
      "Fold 3 Epoch 38/100, Loss: 2.0293, Val Loss: 2.0056, F1 Score: 0.7610\n",
      "Fold 3 Epoch 39/100, Loss: 2.0265, Val Loss: 2.0037, F1 Score: 0.7610\n",
      "Fold 3 Epoch 40/100, Loss: 2.0248, Val Loss: 2.0012, F1 Score: 0.7606\n",
      "Fold 3 Epoch 41/100, Loss: 2.0205, Val Loss: 1.9995, F1 Score: 0.7616\n",
      "Fold 3 Epoch 42/100, Loss: 2.0189, Val Loss: 1.9964, F1 Score: 0.7610\n",
      "Fold 3 Epoch 43/100, Loss: 2.0140, Val Loss: 1.9911, F1 Score: 0.8069\n",
      "Fold 3 Epoch 44/100, Loss: 2.0081, Val Loss: 1.9821, F1 Score: 0.8194\n",
      "Fold 3 Epoch 45/100, Loss: 1.9995, Val Loss: 1.9715, F1 Score: 0.8198\n",
      "Fold 3 Epoch 46/100, Loss: 1.9889, Val Loss: 1.9657, F1 Score: 0.8198\n",
      "Fold 3 Epoch 47/100, Loss: 1.9841, Val Loss: 1.9628, F1 Score: 0.8224\n",
      "Fold 3 Epoch 48/100, Loss: 1.9814, Val Loss: 1.9618, F1 Score: 0.8211\n",
      "Fold 3 Epoch 49/100, Loss: 1.9806, Val Loss: 1.9608, F1 Score: 0.8224\n",
      "Fold 3 Epoch 50/100, Loss: 1.9787, Val Loss: 1.9609, F1 Score: 0.8205\n",
      "Fold 3 Epoch 51/100, Loss: 1.9778, Val Loss: 1.9598, F1 Score: 0.8217\n",
      "Fold 3 Epoch 52/100, Loss: 1.9760, Val Loss: 1.9602, F1 Score: 0.8232\n",
      "Fold 3 Epoch 53/100, Loss: 1.9755, Val Loss: 1.9598, F1 Score: 0.8234\n",
      "Fold 3 Epoch 54/100, Loss: 1.9753, Val Loss: 1.9594, F1 Score: 0.8217\n",
      "Fold 3 Epoch 55/100, Loss: 1.9747, Val Loss: 1.9587, F1 Score: 0.8232\n",
      "Fold 3 Epoch 56/100, Loss: 1.9762, Val Loss: 1.9581, F1 Score: 0.8249\n",
      "Fold 3 Epoch 57/100, Loss: 1.9745, Val Loss: 1.9575, F1 Score: 0.8257\n",
      "Fold 3 Epoch 58/100, Loss: 1.9741, Val Loss: 1.9576, F1 Score: 0.8257\n",
      "Fold 3 Epoch 59/100, Loss: 1.9749, Val Loss: 1.9573, F1 Score: 0.8256\n",
      "Fold 3 Epoch 60/100, Loss: 1.9740, Val Loss: 1.9571, F1 Score: 0.8255\n",
      "Fold 3 Epoch 61/100, Loss: 1.9740, Val Loss: 1.9569, F1 Score: 0.8255\n",
      "Fold 3 Epoch 62/100, Loss: 1.9727, Val Loss: 1.9568, F1 Score: 0.8255\n",
      "Fold 3 Epoch 63/100, Loss: 1.9755, Val Loss: 1.9569, F1 Score: 0.8257\n",
      "Fold 3 Epoch 64/100, Loss: 1.9731, Val Loss: 1.9569, F1 Score: 0.8255\n",
      "Fold 3 Epoch 65/100, Loss: 1.9735, Val Loss: 1.9567, F1 Score: 0.8255\n",
      "Fold 3 Epoch 66/100, Loss: 1.9735, Val Loss: 1.9567, F1 Score: 0.8255\n",
      "Fold 3 Epoch 67/100, Loss: 1.9725, Val Loss: 1.9566, F1 Score: 0.8255\n",
      "Fold 3 Epoch 68/100, Loss: 1.9716, Val Loss: 1.9564, F1 Score: 0.8246\n",
      "Fold 3 Epoch 69/100, Loss: 1.9733, Val Loss: 1.9564, F1 Score: 0.8255\n",
      "Fold 3 Epoch 70/100, Loss: 1.9710, Val Loss: 1.9561, F1 Score: 0.8255\n",
      "Fold 3 Epoch 71/100, Loss: 1.9722, Val Loss: 1.9558, F1 Score: 0.8251\n",
      "Fold 3 Epoch 72/100, Loss: 1.9725, Val Loss: 1.9556, F1 Score: 0.8256\n",
      "Fold 3 Epoch 73/100, Loss: 1.9724, Val Loss: 1.9552, F1 Score: 0.8256\n",
      "Fold 3 Epoch 74/100, Loss: 1.9712, Val Loss: 1.9544, F1 Score: 0.8256\n",
      "Fold 3 Epoch 75/100, Loss: 1.9699, Val Loss: 1.9535, F1 Score: 0.8256\n",
      "Fold 3 Epoch 76/100, Loss: 1.9690, Val Loss: 1.9520, F1 Score: 0.8257\n",
      "Fold 3 Epoch 77/100, Loss: 1.9701, Val Loss: 1.9503, F1 Score: 0.8261\n",
      "Fold 3 Epoch 78/100, Loss: 1.9666, Val Loss: 1.9481, F1 Score: 0.8459\n",
      "Fold 3 Epoch 79/100, Loss: 1.9645, Val Loss: 1.9449, F1 Score: 0.8674\n",
      "Fold 3 Epoch 80/100, Loss: 1.9612, Val Loss: 1.9399, F1 Score: 0.8674\n",
      "Fold 3 Epoch 81/100, Loss: 1.9554, Val Loss: 1.9364, F1 Score: 0.8673\n",
      "Fold 3 Epoch 82/100, Loss: 1.9553, Val Loss: 1.9347, F1 Score: 0.8673\n",
      "Fold 3 Epoch 83/100, Loss: 1.9516, Val Loss: 1.9329, F1 Score: 0.8673\n",
      "Fold 3 Epoch 84/100, Loss: 1.9498, Val Loss: 1.9323, F1 Score: 0.8673\n",
      "Fold 3 Epoch 85/100, Loss: 1.9487, Val Loss: 1.9324, F1 Score: 0.8673\n",
      "Fold 3 Epoch 86/100, Loss: 1.9491, Val Loss: 1.9320, F1 Score: 0.8673\n",
      "Fold 3 Epoch 87/100, Loss: 1.9479, Val Loss: 1.9320, F1 Score: 0.8673\n",
      "Fold 3 Epoch 88/100, Loss: 1.9482, Val Loss: 1.9316, F1 Score: 0.8673\n",
      "Fold 3 Epoch 89/100, Loss: 1.9466, Val Loss: 1.9314, F1 Score: 0.8673\n",
      "Fold 3 Epoch 90/100, Loss: 1.9454, Val Loss: 1.9308, F1 Score: 0.8674\n",
      "Fold 3 Epoch 91/100, Loss: 1.9453, Val Loss: 1.9308, F1 Score: 0.8673\n",
      "Fold 3 Epoch 92/100, Loss: 1.9461, Val Loss: 1.9307, F1 Score: 0.8673\n",
      "Fold 3 Epoch 93/100, Loss: 1.9461, Val Loss: 1.9307, F1 Score: 0.8673\n",
      "Fold 3 Epoch 94/100, Loss: 1.9444, Val Loss: 1.9306, F1 Score: 0.8673\n",
      "Fold 3 Epoch 95/100, Loss: 1.9461, Val Loss: 1.9306, F1 Score: 0.8673\n",
      "Fold 3 Epoch 96/100, Loss: 1.9445, Val Loss: 1.9307, F1 Score: 0.8673\n",
      "Fold 3 Epoch 97/100, Loss: 1.9444, Val Loss: 1.9307, F1 Score: 0.8673\n",
      "Fold 3 Epoch 98/100, Loss: 1.9457, Val Loss: 1.9306, F1 Score: 0.8673\n",
      "Fold 3 Epoch 99/100, Loss: 1.9440, Val Loss: 1.9306, F1 Score: 0.8673\n",
      "Fold 3 Epoch 100/100, Loss: 1.9432, Val Loss: 1.9305, F1 Score: 0.8673\n",
      "Starting Fold 4\n",
      "Fold 4 Epoch 1/100, Loss: 2.7031, Val Loss: 2.6967, F1 Score: 0.2076\n",
      "Fold 4 Epoch 2/100, Loss: 2.6874, Val Loss: 2.6764, F1 Score: 0.2076\n",
      "Fold 4 Epoch 3/100, Loss: 2.6548, Val Loss: 2.6234, F1 Score: 0.2076\n",
      "Fold 4 Epoch 4/100, Loss: 2.4970, Val Loss: 2.3885, F1 Score: 0.2076\n",
      "Fold 4 Epoch 5/100, Loss: 2.3114, Val Loss: 2.1702, F1 Score: 0.5775\n",
      "Fold 4 Epoch 6/100, Loss: 2.1548, Val Loss: 2.1472, F1 Score: 0.5769\n",
      "Fold 4 Epoch 7/100, Loss: 2.1439, Val Loss: 2.1457, F1 Score: 0.5766\n",
      "Fold 4 Epoch 8/100, Loss: 2.1422, Val Loss: 2.1451, F1 Score: 0.5611\n",
      "Fold 4 Epoch 9/100, Loss: 2.1407, Val Loss: 2.1443, F1 Score: 0.5611\n",
      "Fold 4 Epoch 10/100, Loss: 2.1371, Val Loss: 2.1439, F1 Score: 0.5568\n",
      "Fold 4 Epoch 11/100, Loss: 2.1369, Val Loss: 2.1430, F1 Score: 0.5577\n",
      "Fold 4 Epoch 12/100, Loss: 2.1369, Val Loss: 2.1418, F1 Score: 0.5567\n",
      "Fold 4 Epoch 13/100, Loss: 2.1340, Val Loss: 2.1405, F1 Score: 0.5556\n",
      "Fold 4 Epoch 14/100, Loss: 2.1349, Val Loss: 2.1389, F1 Score: 0.5556\n",
      "Fold 4 Epoch 15/100, Loss: 2.1308, Val Loss: 2.1369, F1 Score: 0.5558\n",
      "Fold 4 Epoch 16/100, Loss: 2.1291, Val Loss: 2.1350, F1 Score: 0.5550\n",
      "Fold 4 Epoch 17/100, Loss: 2.1281, Val Loss: 2.1325, F1 Score: 0.5564\n",
      "Fold 4 Epoch 18/100, Loss: 2.1260, Val Loss: 2.1296, F1 Score: 0.5601\n",
      "Fold 4 Epoch 19/100, Loss: 2.1230, Val Loss: 2.1260, F1 Score: 0.5610\n",
      "Fold 4 Epoch 20/100, Loss: 2.1189, Val Loss: 2.1208, F1 Score: 0.5696\n",
      "Fold 4 Epoch 21/100, Loss: 2.1134, Val Loss: 2.1113, F1 Score: 0.6895\n",
      "Fold 4 Epoch 22/100, Loss: 2.1039, Val Loss: 2.0958, F1 Score: 0.6905\n",
      "Fold 4 Epoch 23/100, Loss: 2.0894, Val Loss: 2.0866, F1 Score: 0.6905\n",
      "Fold 4 Epoch 24/100, Loss: 2.0840, Val Loss: 2.0817, F1 Score: 0.6905\n",
      "Fold 4 Epoch 25/100, Loss: 2.0803, Val Loss: 2.0781, F1 Score: 0.6905\n",
      "Fold 4 Epoch 26/100, Loss: 2.0765, Val Loss: 2.0751, F1 Score: 0.6884\n",
      "Fold 4 Epoch 27/100, Loss: 2.0742, Val Loss: 2.0721, F1 Score: 0.6848\n",
      "Fold 4 Epoch 28/100, Loss: 2.0706, Val Loss: 2.0687, F1 Score: 0.6826\n",
      "Fold 4 Epoch 29/100, Loss: 2.0667, Val Loss: 2.0644, F1 Score: 0.7452\n",
      "Fold 4 Epoch 30/100, Loss: 2.0624, Val Loss: 2.0578, F1 Score: 0.7416\n",
      "Fold 4 Epoch 31/100, Loss: 2.0555, Val Loss: 2.0475, F1 Score: 0.7458\n",
      "Fold 4 Epoch 32/100, Loss: 2.0476, Val Loss: 2.0401, F1 Score: 0.7436\n",
      "Fold 4 Epoch 33/100, Loss: 2.0394, Val Loss: 2.0311, F1 Score: 0.7467\n",
      "Fold 4 Epoch 34/100, Loss: 2.0334, Val Loss: 2.0239, F1 Score: 0.7589\n",
      "Fold 4 Epoch 35/100, Loss: 2.0275, Val Loss: 2.0181, F1 Score: 0.7585\n",
      "Fold 4 Epoch 36/100, Loss: 2.0248, Val Loss: 2.0146, F1 Score: 0.7605\n",
      "Fold 4 Epoch 37/100, Loss: 2.0215, Val Loss: 2.0117, F1 Score: 0.7597\n",
      "Fold 4 Epoch 38/100, Loss: 2.0184, Val Loss: 2.0086, F1 Score: 0.7601\n",
      "Fold 4 Epoch 39/100, Loss: 2.0161, Val Loss: 2.0053, F1 Score: 0.7642\n",
      "Fold 4 Epoch 40/100, Loss: 2.0128, Val Loss: 1.9996, F1 Score: 0.8080\n",
      "Fold 4 Epoch 41/100, Loss: 2.0061, Val Loss: 1.9912, F1 Score: 0.8159\n",
      "Fold 4 Epoch 42/100, Loss: 1.9974, Val Loss: 1.9813, F1 Score: 0.8170\n",
      "Fold 4 Epoch 43/100, Loss: 1.9891, Val Loss: 1.9753, F1 Score: 0.8172\n",
      "Fold 4 Epoch 44/100, Loss: 1.9861, Val Loss: 1.9719, F1 Score: 0.8170\n",
      "Fold 4 Epoch 45/100, Loss: 1.9822, Val Loss: 1.9703, F1 Score: 0.8170\n",
      "Fold 4 Epoch 46/100, Loss: 1.9792, Val Loss: 1.9696, F1 Score: 0.8170\n",
      "Fold 4 Epoch 47/100, Loss: 1.9773, Val Loss: 1.9686, F1 Score: 0.8168\n",
      "Fold 4 Epoch 48/100, Loss: 1.9754, Val Loss: 1.9681, F1 Score: 0.8168\n",
      "Fold 4 Epoch 49/100, Loss: 1.9771, Val Loss: 1.9677, F1 Score: 0.8167\n",
      "Fold 4 Epoch 50/100, Loss: 1.9763, Val Loss: 1.9673, F1 Score: 0.8178\n",
      "Fold 4 Epoch 51/100, Loss: 1.9746, Val Loss: 1.9673, F1 Score: 0.8175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Epoch 52/100, Loss: 1.9741, Val Loss: 1.9671, F1 Score: 0.8179\n",
      "Fold 4 Epoch 53/100, Loss: 1.9740, Val Loss: 1.9669, F1 Score: 0.8175\n",
      "Fold 4 Epoch 54/100, Loss: 1.9728, Val Loss: 1.9666, F1 Score: 0.8176\n",
      "Fold 4 Epoch 55/100, Loss: 1.9735, Val Loss: 1.9666, F1 Score: 0.8175\n",
      "Fold 4 Epoch 56/100, Loss: 1.9721, Val Loss: 1.9664, F1 Score: 0.8175\n",
      "Fold 4 Epoch 57/100, Loss: 1.9737, Val Loss: 1.9662, F1 Score: 0.8200\n",
      "Fold 4 Epoch 58/100, Loss: 1.9727, Val Loss: 1.9659, F1 Score: 0.8205\n",
      "Fold 4 Epoch 59/100, Loss: 1.9719, Val Loss: 1.9658, F1 Score: 0.8175\n",
      "Fold 4 Epoch 60/100, Loss: 1.9709, Val Loss: 1.9655, F1 Score: 0.8205\n",
      "Fold 4 Epoch 61/100, Loss: 1.9722, Val Loss: 1.9652, F1 Score: 0.8182\n",
      "Fold 4 Epoch 62/100, Loss: 1.9718, Val Loss: 1.9645, F1 Score: 0.8210\n",
      "Fold 4 Epoch 63/100, Loss: 1.9705, Val Loss: 1.9637, F1 Score: 0.8198\n",
      "Fold 4 Epoch 64/100, Loss: 1.9698, Val Loss: 1.9626, F1 Score: 0.8179\n",
      "Fold 4 Epoch 65/100, Loss: 1.9679, Val Loss: 1.9614, F1 Score: 0.8194\n",
      "Fold 4 Epoch 66/100, Loss: 1.9673, Val Loss: 1.9598, F1 Score: 0.8204\n",
      "Fold 4 Epoch 67/100, Loss: 1.9656, Val Loss: 1.9579, F1 Score: 0.8220\n",
      "Fold 4 Epoch 68/100, Loss: 1.9668, Val Loss: 1.9552, F1 Score: 0.8592\n",
      "Fold 4 Epoch 69/100, Loss: 1.9614, Val Loss: 1.9508, F1 Score: 0.8592\n",
      "Fold 4 Epoch 70/100, Loss: 1.9594, Val Loss: 1.9468, F1 Score: 0.8604\n",
      "Fold 4 Epoch 71/100, Loss: 1.9548, Val Loss: 1.9436, F1 Score: 0.8604\n",
      "Fold 4 Epoch 72/100, Loss: 1.9530, Val Loss: 1.9430, F1 Score: 0.8604\n",
      "Fold 4 Epoch 73/100, Loss: 1.9523, Val Loss: 1.9414, F1 Score: 0.8604\n",
      "Fold 4 Epoch 74/100, Loss: 1.9495, Val Loss: 1.9409, F1 Score: 0.8604\n",
      "Fold 4 Epoch 75/100, Loss: 1.9489, Val Loss: 1.9405, F1 Score: 0.8604\n",
      "Fold 4 Epoch 76/100, Loss: 1.9483, Val Loss: 1.9404, F1 Score: 0.8604\n",
      "Fold 4 Epoch 77/100, Loss: 1.9473, Val Loss: 1.9399, F1 Score: 0.8604\n",
      "Fold 4 Epoch 78/100, Loss: 1.9480, Val Loss: 1.9399, F1 Score: 0.8603\n",
      "Fold 4 Epoch 79/100, Loss: 1.9489, Val Loss: 1.9400, F1 Score: 0.8604\n",
      "Fold 4 Epoch 80/100, Loss: 1.9456, Val Loss: 1.9396, F1 Score: 0.8604\n",
      "Fold 4 Epoch 81/100, Loss: 1.9450, Val Loss: 1.9395, F1 Score: 0.8604\n",
      "Fold 4 Epoch 82/100, Loss: 1.9449, Val Loss: 1.9395, F1 Score: 0.8604\n",
      "Fold 4 Epoch 83/100, Loss: 1.9441, Val Loss: 1.9393, F1 Score: 0.8604\n",
      "Fold 4 Epoch 84/100, Loss: 1.9453, Val Loss: 1.9392, F1 Score: 0.8604\n",
      "Fold 4 Epoch 85/100, Loss: 1.9446, Val Loss: 1.9391, F1 Score: 0.8604\n",
      "Fold 4 Epoch 86/100, Loss: 1.9454, Val Loss: 1.9394, F1 Score: 0.8604\n",
      "Fold 4 Epoch 87/100, Loss: 1.9441, Val Loss: 1.9394, F1 Score: 0.8604\n",
      "Fold 4 Epoch 88/100, Loss: 1.9443, Val Loss: 1.9392, F1 Score: 0.8604\n",
      "Fold 4 Epoch 89/100, Loss: 1.9432, Val Loss: 1.9393, F1 Score: 0.8603\n",
      "Fold 4 Epoch 90/100, Loss: 1.9449, Val Loss: 1.9391, F1 Score: 0.8603\n",
      "Fold 4 Epoch 91/100, Loss: 1.9437, Val Loss: 1.9392, F1 Score: 0.8604\n",
      "Fold 4 Epoch 92/100, Loss: 1.9422, Val Loss: 1.9391, F1 Score: 0.8604\n",
      "Fold 4 Epoch 93/100, Loss: 1.9425, Val Loss: 1.9392, F1 Score: 0.8605\n",
      "Fold 4 Epoch 94/100, Loss: 1.9435, Val Loss: 1.9393, F1 Score: 0.8605\n",
      "Fold 4 Epoch 95/100, Loss: 1.9425, Val Loss: 1.9392, F1 Score: 0.8604\n",
      "Fold 4 Epoch 96/100, Loss: 1.9452, Val Loss: 1.9393, F1 Score: 0.8603\n",
      "Fold 4 Epoch 97/100, Loss: 1.9442, Val Loss: 1.9392, F1 Score: 0.8604\n",
      "Fold 4 Epoch 98/100, Loss: 1.9428, Val Loss: 1.9391, F1 Score: 0.8604\n",
      "Fold 4 Epoch 99/100, Loss: 1.9427, Val Loss: 1.9391, F1 Score: 0.8604\n",
      "Fold 4 Epoch 100/100, Loss: 1.9426, Val Loss: 1.9392, F1 Score: 0.8603\n",
      "Starting Fold 5\n",
      "Fold 5 Epoch 1/100, Loss: 2.6968, Val Loss: 2.6879, F1 Score: 0.2076\n",
      "Fold 5 Epoch 2/100, Loss: 2.6751, Val Loss: 2.6574, F1 Score: 0.2076\n",
      "Fold 5 Epoch 3/100, Loss: 2.6099, Val Loss: 2.5056, F1 Score: 0.2076\n",
      "Fold 5 Epoch 4/100, Loss: 2.3804, Val Loss: 2.2483, F1 Score: 0.5615\n",
      "Fold 5 Epoch 5/100, Loss: 2.1677, Val Loss: 2.1403, F1 Score: 0.5751\n",
      "Fold 5 Epoch 6/100, Loss: 2.1430, Val Loss: 2.1364, F1 Score: 0.5745\n",
      "Fold 5 Epoch 7/100, Loss: 2.1414, Val Loss: 2.1346, F1 Score: 0.5695\n",
      "Fold 5 Epoch 8/100, Loss: 2.1399, Val Loss: 2.1336, F1 Score: 0.5627\n",
      "Fold 5 Epoch 9/100, Loss: 2.1393, Val Loss: 2.1331, F1 Score: 0.5605\n",
      "Fold 5 Epoch 10/100, Loss: 2.1363, Val Loss: 2.1325, F1 Score: 0.5704\n",
      "Fold 5 Epoch 11/100, Loss: 2.1364, Val Loss: 2.1316, F1 Score: 0.5613\n",
      "Fold 5 Epoch 12/100, Loss: 2.1353, Val Loss: 2.1310, F1 Score: 0.5679\n",
      "Fold 5 Epoch 13/100, Loss: 2.1355, Val Loss: 2.1301, F1 Score: 0.5602\n",
      "Fold 5 Epoch 14/100, Loss: 2.1343, Val Loss: 2.1292, F1 Score: 0.5605\n",
      "Fold 5 Epoch 15/100, Loss: 2.1332, Val Loss: 2.1281, F1 Score: 0.5645\n",
      "Fold 5 Epoch 16/100, Loss: 2.1308, Val Loss: 2.1271, F1 Score: 0.5637\n",
      "Fold 5 Epoch 17/100, Loss: 2.1295, Val Loss: 2.1259, F1 Score: 0.5568\n",
      "Fold 5 Epoch 18/100, Loss: 2.1291, Val Loss: 2.1247, F1 Score: 0.5614\n",
      "Fold 5 Epoch 19/100, Loss: 2.1280, Val Loss: 2.1234, F1 Score: 0.5615\n",
      "Fold 5 Epoch 20/100, Loss: 2.1270, Val Loss: 2.1219, F1 Score: 0.5614\n",
      "Fold 5 Epoch 21/100, Loss: 2.1256, Val Loss: 2.1201, F1 Score: 0.5616\n",
      "Fold 5 Epoch 22/100, Loss: 2.1218, Val Loss: 2.1176, F1 Score: 0.5662\n",
      "Fold 5 Epoch 23/100, Loss: 2.1200, Val Loss: 2.1135, F1 Score: 0.5666\n",
      "Fold 5 Epoch 24/100, Loss: 2.1151, Val Loss: 2.1034, F1 Score: 0.6798\n",
      "Fold 5 Epoch 25/100, Loss: 2.1012, Val Loss: 2.0824, F1 Score: 0.6872\n",
      "Fold 5 Epoch 26/100, Loss: 2.0836, Val Loss: 2.0758, F1 Score: 0.6882\n",
      "Fold 5 Epoch 27/100, Loss: 2.0791, Val Loss: 2.0720, F1 Score: 0.6882\n",
      "Fold 5 Epoch 28/100, Loss: 2.0720, Val Loss: 2.0677, F1 Score: 0.6813\n",
      "Fold 5 Epoch 29/100, Loss: 2.0682, Val Loss: 2.0640, F1 Score: 0.6914\n",
      "Fold 5 Epoch 30/100, Loss: 2.0618, Val Loss: 2.0579, F1 Score: 0.7571\n",
      "Fold 5 Epoch 31/100, Loss: 2.0582, Val Loss: 2.0489, F1 Score: 0.7586\n",
      "Fold 5 Epoch 32/100, Loss: 2.0485, Val Loss: 2.0409, F1 Score: 0.7586\n",
      "Fold 5 Epoch 33/100, Loss: 2.0418, Val Loss: 2.0329, F1 Score: 0.7594\n",
      "Fold 5 Epoch 34/100, Loss: 2.0346, Val Loss: 2.0276, F1 Score: 0.7585\n",
      "Fold 5 Epoch 35/100, Loss: 2.0317, Val Loss: 2.0235, F1 Score: 0.7541\n",
      "Fold 5 Epoch 36/100, Loss: 2.0283, Val Loss: 2.0199, F1 Score: 0.7563\n",
      "Fold 5 Epoch 37/100, Loss: 2.0219, Val Loss: 2.0159, F1 Score: 0.7569\n",
      "Fold 5 Epoch 38/100, Loss: 2.0180, Val Loss: 2.0103, F1 Score: 0.7838\n",
      "Fold 5 Epoch 39/100, Loss: 2.0126, Val Loss: 2.0067, F1 Score: 0.7905\n",
      "Fold 5 Epoch 40/100, Loss: 2.0091, Val Loss: 2.0028, F1 Score: 0.8011\n",
      "Fold 5 Epoch 41/100, Loss: 2.0062, Val Loss: 1.9990, F1 Score: 0.8100\n",
      "Fold 5 Epoch 42/100, Loss: 2.0010, Val Loss: 1.9957, F1 Score: 0.8100\n",
      "Fold 5 Epoch 43/100, Loss: 1.9978, Val Loss: 1.9917, F1 Score: 0.8101\n",
      "Fold 5 Epoch 44/100, Loss: 1.9933, Val Loss: 1.9898, F1 Score: 0.8100\n",
      "Fold 5 Epoch 45/100, Loss: 1.9896, Val Loss: 1.9882, F1 Score: 0.8100\n",
      "Fold 5 Epoch 46/100, Loss: 1.9885, Val Loss: 1.9842, F1 Score: 0.8101\n",
      "Fold 5 Epoch 47/100, Loss: 1.9867, Val Loss: 1.9832, F1 Score: 0.8100\n",
      "Fold 5 Epoch 48/100, Loss: 1.9818, Val Loss: 1.9813, F1 Score: 0.8100\n",
      "Fold 5 Epoch 49/100, Loss: 1.9815, Val Loss: 1.9800, F1 Score: 0.8083\n",
      "Fold 5 Epoch 50/100, Loss: 1.9830, Val Loss: 1.9792, F1 Score: 0.8083\n",
      "Fold 5 Epoch 51/100, Loss: 1.9796, Val Loss: 1.9783, F1 Score: 0.8083\n",
      "Fold 5 Epoch 52/100, Loss: 1.9773, Val Loss: 1.9778, F1 Score: 0.8083\n",
      "Fold 5 Epoch 53/100, Loss: 1.9778, Val Loss: 1.9775, F1 Score: 0.8083\n",
      "Fold 5 Epoch 54/100, Loss: 1.9761, Val Loss: 1.9773, F1 Score: 0.8083\n",
      "Fold 5 Epoch 55/100, Loss: 1.9749, Val Loss: 1.9774, F1 Score: 0.8083\n",
      "Fold 5 Epoch 56/100, Loss: 1.9745, Val Loss: 1.9769, F1 Score: 0.8086\n",
      "Fold 5 Epoch 57/100, Loss: 1.9753, Val Loss: 1.9769, F1 Score: 0.8083\n",
      "Fold 5 Epoch 58/100, Loss: 1.9745, Val Loss: 1.9767, F1 Score: 0.8085\n",
      "Fold 5 Epoch 59/100, Loss: 1.9759, Val Loss: 1.9765, F1 Score: 0.8100\n",
      "Fold 5 Epoch 60/100, Loss: 1.9730, Val Loss: 1.9764, F1 Score: 0.8085\n",
      "Fold 5 Epoch 61/100, Loss: 1.9741, Val Loss: 1.9765, F1 Score: 0.8087\n",
      "Fold 5 Epoch 62/100, Loss: 1.9749, Val Loss: 1.9763, F1 Score: 0.8087\n",
      "Fold 5 Epoch 63/100, Loss: 1.9715, Val Loss: 1.9760, F1 Score: 0.8083\n",
      "Fold 5 Epoch 64/100, Loss: 1.9715, Val Loss: 1.9760, F1 Score: 0.8083\n",
      "Fold 5 Epoch 65/100, Loss: 1.9731, Val Loss: 1.9758, F1 Score: 0.8083\n",
      "Fold 5 Epoch 66/100, Loss: 1.9726, Val Loss: 1.9758, F1 Score: 0.8083\n",
      "Fold 5 Epoch 67/100, Loss: 1.9725, Val Loss: 1.9759, F1 Score: 0.8083\n",
      "Fold 5 Epoch 68/100, Loss: 1.9722, Val Loss: 1.9757, F1 Score: 0.8083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Epoch 69/100, Loss: 1.9728, Val Loss: 1.9756, F1 Score: 0.8083\n",
      "Fold 5 Epoch 70/100, Loss: 1.9717, Val Loss: 1.9759, F1 Score: 0.8097\n",
      "Fold 5 Epoch 71/100, Loss: 1.9706, Val Loss: 1.9755, F1 Score: 0.8083\n",
      "Fold 5 Epoch 72/100, Loss: 1.9713, Val Loss: 1.9758, F1 Score: 0.8083\n",
      "Fold 5 Epoch 73/100, Loss: 1.9717, Val Loss: 1.9753, F1 Score: 0.8097\n",
      "Fold 5 Epoch 74/100, Loss: 1.9728, Val Loss: 1.9754, F1 Score: 0.8104\n",
      "Fold 5 Epoch 75/100, Loss: 1.9713, Val Loss: 1.9755, F1 Score: 0.8083\n",
      "Fold 5 Epoch 76/100, Loss: 1.9708, Val Loss: 1.9759, F1 Score: 0.8086\n",
      "Fold 5 Epoch 77/100, Loss: 1.9707, Val Loss: 1.9759, F1 Score: 0.8086\n",
      "Fold 5 Epoch 78/100, Loss: 1.9713, Val Loss: 1.9754, F1 Score: 0.8083\n",
      "Fold 5 Epoch 79/100, Loss: 1.9715, Val Loss: 1.9756, F1 Score: 0.8089\n",
      "Fold 5 Epoch 80/100, Loss: 1.9716, Val Loss: 1.9752, F1 Score: 0.8096\n",
      "Fold 5 Epoch 81/100, Loss: 1.9701, Val Loss: 1.9757, F1 Score: 0.8083\n",
      "Fold 5 Epoch 82/100, Loss: 1.9713, Val Loss: 1.9753, F1 Score: 0.8083\n",
      "Fold 5 Epoch 83/100, Loss: 1.9715, Val Loss: 1.9752, F1 Score: 0.8098\n",
      "Fold 5 Epoch 84/100, Loss: 1.9700, Val Loss: 1.9754, F1 Score: 0.8086\n",
      "Fold 5 Epoch 85/100, Loss: 1.9700, Val Loss: 1.9750, F1 Score: 0.8095\n",
      "Fold 5 Epoch 86/100, Loss: 1.9724, Val Loss: 1.9750, F1 Score: 0.8098\n",
      "Fold 5 Epoch 87/100, Loss: 1.9698, Val Loss: 1.9751, F1 Score: 0.8095\n",
      "Fold 5 Epoch 88/100, Loss: 1.9712, Val Loss: 1.9752, F1 Score: 0.8096\n",
      "Fold 5 Epoch 89/100, Loss: 1.9699, Val Loss: 1.9749, F1 Score: 0.8095\n",
      "Fold 5 Epoch 90/100, Loss: 1.9705, Val Loss: 1.9753, F1 Score: 0.8101\n",
      "Fold 5 Epoch 91/100, Loss: 1.9712, Val Loss: 1.9748, F1 Score: 0.8096\n",
      "Fold 5 Epoch 92/100, Loss: 1.9701, Val Loss: 1.9748, F1 Score: 0.8095\n",
      "Fold 5 Epoch 93/100, Loss: 1.9701, Val Loss: 1.9749, F1 Score: 0.8096\n",
      "Fold 5 Epoch 94/100, Loss: 1.9692, Val Loss: 1.9751, F1 Score: 0.8095\n",
      "Fold 5 Epoch 95/100, Loss: 1.9720, Val Loss: 1.9750, F1 Score: 0.8097\n",
      "Fold 5 Epoch 96/100, Loss: 1.9704, Val Loss: 1.9754, F1 Score: 0.8080\n",
      "Fold 5 Epoch 97/100, Loss: 1.9704, Val Loss: 1.9750, F1 Score: 0.8096\n",
      "Fold 5 Epoch 98/100, Loss: 1.9696, Val Loss: 1.9750, F1 Score: 0.8098\n",
      "Fold 5 Epoch 99/100, Loss: 1.9705, Val Loss: 1.9750, F1 Score: 0.8098\n",
      "Fold 5 Epoch 100/100, Loss: 1.9697, Val Loss: 1.9751, F1 Score: 0.8095\n",
      "Starting Fold 6\n",
      "Fold 6 Epoch 1/100, Loss: 2.7039, Val Loss: 2.6967, F1 Score: 0.1639\n",
      "Fold 6 Epoch 2/100, Loss: 2.6874, Val Loss: 2.6754, F1 Score: 0.1639\n",
      "Fold 6 Epoch 3/100, Loss: 2.6543, Val Loss: 2.6212, F1 Score: 0.2076\n",
      "Fold 6 Epoch 4/100, Loss: 2.5215, Val Loss: 2.3921, F1 Score: 0.2076\n",
      "Fold 6 Epoch 5/100, Loss: 2.3043, Val Loss: 2.1675, F1 Score: 0.5682\n",
      "Fold 6 Epoch 6/100, Loss: 2.1530, Val Loss: 2.1480, F1 Score: 0.5664\n",
      "Fold 6 Epoch 7/100, Loss: 2.1436, Val Loss: 2.1454, F1 Score: 0.5664\n",
      "Fold 6 Epoch 8/100, Loss: 2.1406, Val Loss: 2.1440, F1 Score: 0.5599\n",
      "Fold 6 Epoch 9/100, Loss: 2.1389, Val Loss: 2.1439, F1 Score: 0.5559\n",
      "Fold 6 Epoch 10/100, Loss: 2.1386, Val Loss: 2.1434, F1 Score: 0.5553\n",
      "Fold 6 Epoch 11/100, Loss: 2.1372, Val Loss: 2.1429, F1 Score: 0.5556\n",
      "Fold 6 Epoch 12/100, Loss: 2.1380, Val Loss: 2.1425, F1 Score: 0.5555\n",
      "Fold 6 Epoch 13/100, Loss: 2.1379, Val Loss: 2.1424, F1 Score: 0.5555\n",
      "Fold 6 Epoch 14/100, Loss: 2.1371, Val Loss: 2.1422, F1 Score: 0.5536\n",
      "Fold 6 Epoch 15/100, Loss: 2.1340, Val Loss: 2.1419, F1 Score: 0.5568\n",
      "Fold 6 Epoch 16/100, Loss: 2.1362, Val Loss: 2.1407, F1 Score: 0.5552\n",
      "Fold 6 Epoch 17/100, Loss: 2.1328, Val Loss: 2.1398, F1 Score: 0.5520\n",
      "Fold 6 Epoch 18/100, Loss: 2.1339, Val Loss: 2.1386, F1 Score: 0.5520\n",
      "Fold 6 Epoch 19/100, Loss: 2.1303, Val Loss: 2.1373, F1 Score: 0.5520\n",
      "Fold 6 Epoch 20/100, Loss: 2.1312, Val Loss: 2.1356, F1 Score: 0.5585\n",
      "Fold 6 Epoch 21/100, Loss: 2.1268, Val Loss: 2.1336, F1 Score: 0.5589\n",
      "Fold 6 Epoch 22/100, Loss: 2.1255, Val Loss: 2.1312, F1 Score: 0.5626\n",
      "Fold 6 Epoch 23/100, Loss: 2.1244, Val Loss: 2.1284, F1 Score: 0.5621\n",
      "Fold 6 Epoch 24/100, Loss: 2.1215, Val Loss: 2.1244, F1 Score: 0.5670\n",
      "Fold 6 Epoch 25/100, Loss: 2.1167, Val Loss: 2.1196, F1 Score: 0.5673\n",
      "Fold 6 Epoch 26/100, Loss: 2.1122, Val Loss: 2.1112, F1 Score: 0.6484\n",
      "Fold 6 Epoch 27/100, Loss: 2.1027, Val Loss: 2.0909, F1 Score: 0.6806\n",
      "Fold 6 Epoch 28/100, Loss: 2.0858, Val Loss: 2.0758, F1 Score: 0.6806\n",
      "Fold 6 Epoch 29/100, Loss: 2.0767, Val Loss: 2.0694, F1 Score: 0.6806\n",
      "Fold 6 Epoch 30/100, Loss: 2.0696, Val Loss: 2.0629, F1 Score: 0.7345\n",
      "Fold 6 Epoch 31/100, Loss: 2.0619, Val Loss: 2.0540, F1 Score: 0.7504\n",
      "Fold 6 Epoch 32/100, Loss: 2.0528, Val Loss: 2.0452, F1 Score: 0.7479\n",
      "Fold 6 Epoch 33/100, Loss: 2.0442, Val Loss: 2.0357, F1 Score: 0.7472\n",
      "Fold 6 Epoch 34/100, Loss: 2.0383, Val Loss: 2.0322, F1 Score: 0.7491\n",
      "Fold 6 Epoch 35/100, Loss: 2.0344, Val Loss: 2.0280, F1 Score: 0.7472\n",
      "Fold 6 Epoch 36/100, Loss: 2.0275, Val Loss: 2.0263, F1 Score: 0.7479\n",
      "Fold 6 Epoch 37/100, Loss: 2.0245, Val Loss: 2.0248, F1 Score: 0.7495\n",
      "Fold 6 Epoch 38/100, Loss: 2.0257, Val Loss: 2.0239, F1 Score: 0.7497\n",
      "Fold 6 Epoch 39/100, Loss: 2.0204, Val Loss: 2.0223, F1 Score: 0.7462\n",
      "Fold 6 Epoch 40/100, Loss: 2.0187, Val Loss: 2.0202, F1 Score: 0.7465\n",
      "Fold 6 Epoch 41/100, Loss: 2.0144, Val Loss: 2.0158, F1 Score: 0.7485\n",
      "Fold 6 Epoch 42/100, Loss: 2.0130, Val Loss: 2.0118, F1 Score: 0.7876\n",
      "Fold 6 Epoch 43/100, Loss: 2.0082, Val Loss: 2.0099, F1 Score: 0.7903\n",
      "Fold 6 Epoch 44/100, Loss: 2.0070, Val Loss: 2.0070, F1 Score: 0.7943\n",
      "Fold 6 Epoch 45/100, Loss: 2.0031, Val Loss: 2.0042, F1 Score: 0.8018\n",
      "Fold 6 Epoch 46/100, Loss: 1.9971, Val Loss: 2.0004, F1 Score: 0.8055\n",
      "Fold 6 Epoch 47/100, Loss: 1.9938, Val Loss: 1.9967, F1 Score: 0.8055\n",
      "Fold 6 Epoch 48/100, Loss: 1.9910, Val Loss: 1.9940, F1 Score: 0.8055\n",
      "Fold 6 Epoch 49/100, Loss: 1.9878, Val Loss: 1.9915, F1 Score: 0.8031\n",
      "Fold 6 Epoch 50/100, Loss: 1.9853, Val Loss: 1.9888, F1 Score: 0.8030\n",
      "Fold 6 Epoch 51/100, Loss: 1.9833, Val Loss: 1.9871, F1 Score: 0.8010\n",
      "Fold 6 Epoch 52/100, Loss: 1.9794, Val Loss: 1.9857, F1 Score: 0.8009\n",
      "Fold 6 Epoch 53/100, Loss: 1.9785, Val Loss: 1.9851, F1 Score: 0.8009\n",
      "Fold 6 Epoch 54/100, Loss: 1.9791, Val Loss: 1.9847, F1 Score: 0.8009\n",
      "Fold 6 Epoch 55/100, Loss: 1.9744, Val Loss: 1.9845, F1 Score: 0.8009\n",
      "Fold 6 Epoch 56/100, Loss: 1.9787, Val Loss: 1.9844, F1 Score: 0.8010\n",
      "Fold 6 Epoch 57/100, Loss: 1.9747, Val Loss: 1.9838, F1 Score: 0.8009\n",
      "Fold 6 Epoch 58/100, Loss: 1.9732, Val Loss: 1.9836, F1 Score: 0.8009\n",
      "Fold 6 Epoch 59/100, Loss: 1.9717, Val Loss: 1.9837, F1 Score: 0.8011\n",
      "Fold 6 Epoch 60/100, Loss: 1.9731, Val Loss: 1.9835, F1 Score: 0.8010\n",
      "Fold 6 Epoch 61/100, Loss: 1.9715, Val Loss: 1.9833, F1 Score: 0.8010\n",
      "Fold 6 Epoch 62/100, Loss: 1.9717, Val Loss: 1.9841, F1 Score: 0.8012\n",
      "Fold 6 Epoch 63/100, Loss: 1.9715, Val Loss: 1.9834, F1 Score: 0.8011\n",
      "Fold 6 Epoch 64/100, Loss: 1.9721, Val Loss: 1.9836, F1 Score: 0.8011\n",
      "Fold 6 Epoch 65/100, Loss: 1.9716, Val Loss: 1.9838, F1 Score: 0.8011\n",
      "Fold 6 Epoch 66/100, Loss: 1.9738, Val Loss: 1.9833, F1 Score: 0.8011\n",
      "Fold 6 Epoch 67/100, Loss: 1.9715, Val Loss: 1.9838, F1 Score: 0.8011\n",
      "Fold 6 Epoch 68/100, Loss: 1.9723, Val Loss: 1.9837, F1 Score: 0.8011\n",
      "Fold 6 Epoch 69/100, Loss: 1.9716, Val Loss: 1.9835, F1 Score: 0.8011\n",
      "Fold 6 Epoch 70/100, Loss: 1.9715, Val Loss: 1.9838, F1 Score: 0.8011\n",
      "Fold 6 Epoch 71/100, Loss: 1.9711, Val Loss: 1.9840, F1 Score: 0.8011\n",
      "Fold 6 Epoch 72/100, Loss: 1.9701, Val Loss: 1.9835, F1 Score: 0.8011\n",
      "Fold 6 Epoch 73/100, Loss: 1.9710, Val Loss: 1.9837, F1 Score: 0.8011\n",
      "Fold 6 Epoch 74/100, Loss: 1.9706, Val Loss: 1.9833, F1 Score: 0.8010\n",
      "Fold 6 Epoch 75/100, Loss: 1.9697, Val Loss: 1.9845, F1 Score: 0.8014\n",
      "Fold 6 Epoch 76/100, Loss: 1.9699, Val Loss: 1.9842, F1 Score: 0.8020\n",
      "Fold 6 Epoch 77/100, Loss: 1.9689, Val Loss: 1.9839, F1 Score: 0.8014\n",
      "Fold 6 Epoch 78/100, Loss: 1.9699, Val Loss: 1.9837, F1 Score: 0.8014\n",
      "Fold 6 Epoch 79/100, Loss: 1.9695, Val Loss: 1.9833, F1 Score: 0.8010\n",
      "Fold 6 Epoch 80/100, Loss: 1.9691, Val Loss: 1.9839, F1 Score: 0.8014\n",
      "Fold 6 Epoch 81/100, Loss: 1.9716, Val Loss: 1.9834, F1 Score: 0.8014\n",
      "Fold 6 Epoch 82/100, Loss: 1.9704, Val Loss: 1.9835, F1 Score: 0.8013\n",
      "Fold 6 Epoch 83/100, Loss: 1.9721, Val Loss: 1.9839, F1 Score: 0.8015\n",
      "Fold 6 Epoch 84/100, Loss: 1.9694, Val Loss: 1.9841, F1 Score: 0.8013\n",
      "Fold 6 Epoch 85/100, Loss: 1.9689, Val Loss: 1.9844, F1 Score: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 Epoch 86/100, Loss: 1.9700, Val Loss: 1.9840, F1 Score: 0.8012\n",
      "Fold 6 Epoch 87/100, Loss: 1.9704, Val Loss: 1.9840, F1 Score: 0.8015\n",
      "Fold 6 Epoch 88/100, Loss: 1.9687, Val Loss: 1.9835, F1 Score: 0.8014\n",
      "Fold 6 Epoch 89/100, Loss: 1.9694, Val Loss: 1.9841, F1 Score: 0.8015\n",
      "Fold 6 Epoch 90/100, Loss: 1.9704, Val Loss: 1.9838, F1 Score: 0.8014\n",
      "Fold 6 Epoch 91/100, Loss: 1.9704, Val Loss: 1.9833, F1 Score: 0.8014\n",
      "Fold 6 Epoch 92/100, Loss: 1.9692, Val Loss: 1.9838, F1 Score: 0.8014\n",
      "Fold 6 Epoch 93/100, Loss: 1.9688, Val Loss: 1.9839, F1 Score: 0.8014\n",
      "Fold 6 Epoch 94/100, Loss: 1.9720, Val Loss: 1.9836, F1 Score: 0.8014\n",
      "Fold 6 Epoch 95/100, Loss: 1.9695, Val Loss: 1.9835, F1 Score: 0.8014\n",
      "Fold 6 Epoch 96/100, Loss: 1.9697, Val Loss: 1.9837, F1 Score: 0.8014\n",
      "Fold 6 Epoch 97/100, Loss: 1.9695, Val Loss: 1.9836, F1 Score: 0.8014\n",
      "Fold 6 Epoch 98/100, Loss: 1.9702, Val Loss: 1.9833, F1 Score: 0.8014\n",
      "Fold 6 Epoch 99/100, Loss: 1.9704, Val Loss: 1.9838, F1 Score: 0.8014\n",
      "Fold 6 Epoch 100/100, Loss: 1.9683, Val Loss: 1.9845, F1 Score: 0.8003\n",
      "Starting Fold 7\n",
      "Fold 7 Epoch 1/100, Loss: 2.7024, Val Loss: 2.6948, F1 Score: 0.2076\n",
      "Fold 7 Epoch 2/100, Loss: 2.6840, Val Loss: 2.6693, F1 Score: 0.2076\n",
      "Fold 7 Epoch 3/100, Loss: 2.6346, Val Loss: 2.5642, F1 Score: 0.2076\n",
      "Fold 7 Epoch 4/100, Loss: 2.4211, Val Loss: 2.3438, F1 Score: 0.2076\n",
      "Fold 7 Epoch 5/100, Loss: 2.2441, Val Loss: 2.1594, F1 Score: 0.5639\n",
      "Fold 7 Epoch 6/100, Loss: 2.1500, Val Loss: 2.1521, F1 Score: 0.5639\n",
      "Fold 7 Epoch 7/100, Loss: 2.1423, Val Loss: 2.1489, F1 Score: 0.5648\n",
      "Fold 7 Epoch 8/100, Loss: 2.1392, Val Loss: 2.1472, F1 Score: 0.5605\n",
      "Fold 7 Epoch 9/100, Loss: 2.1392, Val Loss: 2.1455, F1 Score: 0.5580\n",
      "Fold 7 Epoch 10/100, Loss: 2.1376, Val Loss: 2.1455, F1 Score: 0.5616\n",
      "Fold 7 Epoch 11/100, Loss: 2.1361, Val Loss: 2.1447, F1 Score: 0.5598\n",
      "Fold 7 Epoch 12/100, Loss: 2.1365, Val Loss: 2.1441, F1 Score: 0.5569\n",
      "Fold 7 Epoch 13/100, Loss: 2.1394, Val Loss: 2.1433, F1 Score: 0.5547\n",
      "Fold 7 Epoch 14/100, Loss: 2.1373, Val Loss: 2.1425, F1 Score: 0.5595\n",
      "Fold 7 Epoch 15/100, Loss: 2.1371, Val Loss: 2.1419, F1 Score: 0.5605\n",
      "Fold 7 Epoch 16/100, Loss: 2.1347, Val Loss: 2.1400, F1 Score: 0.5551\n",
      "Fold 7 Epoch 17/100, Loss: 2.1315, Val Loss: 2.1387, F1 Score: 0.5566\n",
      "Fold 7 Epoch 18/100, Loss: 2.1312, Val Loss: 2.1368, F1 Score: 0.5567\n",
      "Fold 7 Epoch 19/100, Loss: 2.1273, Val Loss: 2.1346, F1 Score: 0.5569\n",
      "Fold 7 Epoch 20/100, Loss: 2.1262, Val Loss: 2.1316, F1 Score: 0.5579\n",
      "Fold 7 Epoch 21/100, Loss: 2.1229, Val Loss: 2.1276, F1 Score: 0.5587\n",
      "Fold 7 Epoch 22/100, Loss: 2.1175, Val Loss: 2.1229, F1 Score: 0.5611\n",
      "Fold 7 Epoch 23/100, Loss: 2.1135, Val Loss: 2.1135, F1 Score: 0.6790\n",
      "Fold 7 Epoch 24/100, Loss: 2.1019, Val Loss: 2.0933, F1 Score: 0.6789\n",
      "Fold 7 Epoch 25/100, Loss: 2.0865, Val Loss: 2.0849, F1 Score: 0.6789\n",
      "Fold 7 Epoch 26/100, Loss: 2.0790, Val Loss: 2.0812, F1 Score: 0.6789\n",
      "Fold 7 Epoch 27/100, Loss: 2.0754, Val Loss: 2.0778, F1 Score: 0.6722\n",
      "Fold 7 Epoch 28/100, Loss: 2.0714, Val Loss: 2.0744, F1 Score: 0.6717\n",
      "Fold 7 Epoch 29/100, Loss: 2.0663, Val Loss: 2.0699, F1 Score: 0.7122\n",
      "Fold 7 Epoch 30/100, Loss: 2.0612, Val Loss: 2.0653, F1 Score: 0.7413\n",
      "Fold 7 Epoch 31/100, Loss: 2.0564, Val Loss: 2.0602, F1 Score: 0.7320\n",
      "Fold 7 Epoch 32/100, Loss: 2.0506, Val Loss: 2.0551, F1 Score: 0.7327\n",
      "Fold 7 Epoch 33/100, Loss: 2.0439, Val Loss: 2.0505, F1 Score: 0.7346\n",
      "Fold 7 Epoch 34/100, Loss: 2.0391, Val Loss: 2.0480, F1 Score: 0.7347\n",
      "Fold 7 Epoch 35/100, Loss: 2.0368, Val Loss: 2.0447, F1 Score: 0.7333\n",
      "Fold 7 Epoch 36/100, Loss: 2.0343, Val Loss: 2.0419, F1 Score: 0.7244\n",
      "Fold 7 Epoch 37/100, Loss: 2.0314, Val Loss: 2.0394, F1 Score: 0.7356\n",
      "Fold 7 Epoch 38/100, Loss: 2.0294, Val Loss: 2.0365, F1 Score: 0.7353\n",
      "Fold 7 Epoch 39/100, Loss: 2.0249, Val Loss: 2.0338, F1 Score: 0.7350\n",
      "Fold 7 Epoch 40/100, Loss: 2.0236, Val Loss: 2.0325, F1 Score: 0.7358\n",
      "Fold 7 Epoch 41/100, Loss: 2.0222, Val Loss: 2.0319, F1 Score: 0.7349\n",
      "Fold 7 Epoch 42/100, Loss: 2.0211, Val Loss: 2.0311, F1 Score: 0.7349\n",
      "Fold 7 Epoch 43/100, Loss: 2.0192, Val Loss: 2.0304, F1 Score: 0.7349\n",
      "Fold 7 Epoch 44/100, Loss: 2.0197, Val Loss: 2.0302, F1 Score: 0.7354\n",
      "Fold 7 Epoch 45/100, Loss: 2.0208, Val Loss: 2.0302, F1 Score: 0.7354\n",
      "Fold 7 Epoch 46/100, Loss: 2.0179, Val Loss: 2.0301, F1 Score: 0.7349\n",
      "Fold 7 Epoch 47/100, Loss: 2.0193, Val Loss: 2.0297, F1 Score: 0.7349\n",
      "Fold 7 Epoch 48/100, Loss: 2.0165, Val Loss: 2.0297, F1 Score: 0.7349\n",
      "Fold 7 Epoch 49/100, Loss: 2.0168, Val Loss: 2.0295, F1 Score: 0.7349\n",
      "Fold 7 Epoch 50/100, Loss: 2.0174, Val Loss: 2.0292, F1 Score: 0.7356\n",
      "Fold 7 Epoch 51/100, Loss: 2.0182, Val Loss: 2.0291, F1 Score: 0.7354\n",
      "Fold 7 Epoch 52/100, Loss: 2.0163, Val Loss: 2.0291, F1 Score: 0.7354\n",
      "Fold 7 Epoch 53/100, Loss: 2.0165, Val Loss: 2.0292, F1 Score: 0.7357\n",
      "Fold 7 Epoch 54/100, Loss: 2.0162, Val Loss: 2.0292, F1 Score: 0.7348\n",
      "Fold 7 Epoch 55/100, Loss: 2.0150, Val Loss: 2.0290, F1 Score: 0.7356\n",
      "Fold 7 Epoch 56/100, Loss: 2.0156, Val Loss: 2.0293, F1 Score: 0.7348\n",
      "Fold 7 Epoch 57/100, Loss: 2.0154, Val Loss: 2.0293, F1 Score: 0.7348\n",
      "Fold 7 Epoch 58/100, Loss: 2.0150, Val Loss: 2.0292, F1 Score: 0.7348\n",
      "Fold 7 Epoch 59/100, Loss: 2.0158, Val Loss: 2.0290, F1 Score: 0.7382\n",
      "Fold 7 Epoch 60/100, Loss: 2.0153, Val Loss: 2.0292, F1 Score: 0.7354\n",
      "Fold 7 Epoch 61/100, Loss: 2.0143, Val Loss: 2.0293, F1 Score: 0.7348\n",
      "Fold 7 Epoch 62/100, Loss: 2.0146, Val Loss: 2.0291, F1 Score: 0.7355\n",
      "Fold 7 Epoch 63/100, Loss: 2.0151, Val Loss: 2.0290, F1 Score: 0.7338\n",
      "Fold 7 Epoch 64/100, Loss: 2.0151, Val Loss: 2.0291, F1 Score: 0.7348\n",
      "Fold 7 Epoch 65/100, Loss: 2.0160, Val Loss: 2.0292, F1 Score: 0.7354\n",
      "Fold 7 Epoch 66/100, Loss: 2.0149, Val Loss: 2.0288, F1 Score: 0.7347\n",
      "Fold 7 Epoch 67/100, Loss: 2.0138, Val Loss: 2.0287, F1 Score: 0.7350\n",
      "Fold 7 Epoch 68/100, Loss: 2.0152, Val Loss: 2.0293, F1 Score: 0.7354\n",
      "Fold 7 Epoch 69/100, Loss: 2.0136, Val Loss: 2.0293, F1 Score: 0.7354\n",
      "Fold 7 Epoch 70/100, Loss: 2.0134, Val Loss: 2.0291, F1 Score: 0.7349\n",
      "Fold 7 Epoch 71/100, Loss: 2.0132, Val Loss: 2.0288, F1 Score: 0.7381\n",
      "Fold 7 Epoch 72/100, Loss: 2.0140, Val Loss: 2.0290, F1 Score: 0.7349\n",
      "Fold 7 Epoch 73/100, Loss: 2.0136, Val Loss: 2.0289, F1 Score: 0.7348\n",
      "Fold 7 Epoch 74/100, Loss: 2.0151, Val Loss: 2.0290, F1 Score: 0.7348\n",
      "Fold 7 Epoch 75/100, Loss: 2.0158, Val Loss: 2.0293, F1 Score: 0.7348\n",
      "Fold 7 Epoch 76/100, Loss: 2.0140, Val Loss: 2.0287, F1 Score: 0.7362\n",
      "Fold 7 Epoch 77/100, Loss: 2.0145, Val Loss: 2.0291, F1 Score: 0.7349\n",
      "Fold 7 Epoch 78/100, Loss: 2.0130, Val Loss: 2.0287, F1 Score: 0.7343\n",
      "Fold 7 Epoch 79/100, Loss: 2.0138, Val Loss: 2.0291, F1 Score: 0.7342\n",
      "Fold 7 Epoch 80/100, Loss: 2.0129, Val Loss: 2.0291, F1 Score: 0.7337\n",
      "Fold 7 Epoch 81/100, Loss: 2.0134, Val Loss: 2.0292, F1 Score: 0.7336\n",
      "Fold 7 Epoch 82/100, Loss: 2.0133, Val Loss: 2.0294, F1 Score: 0.7377\n",
      "Fold 7 Epoch 83/100, Loss: 2.0152, Val Loss: 2.0294, F1 Score: 0.7338\n",
      "Fold 7 Epoch 84/100, Loss: 2.0152, Val Loss: 2.0284, F1 Score: 0.7382\n",
      "Fold 7 Epoch 85/100, Loss: 2.0130, Val Loss: 2.0292, F1 Score: 0.7328\n",
      "Fold 7 Epoch 86/100, Loss: 2.0136, Val Loss: 2.0288, F1 Score: 0.7387\n",
      "Fold 7 Epoch 87/100, Loss: 2.0133, Val Loss: 2.0287, F1 Score: 0.7377\n",
      "Fold 7 Epoch 88/100, Loss: 2.0126, Val Loss: 2.0288, F1 Score: 0.7326\n",
      "Fold 7 Epoch 89/100, Loss: 2.0118, Val Loss: 2.0279, F1 Score: 0.7378\n",
      "Fold 7 Epoch 90/100, Loss: 2.0130, Val Loss: 2.0269, F1 Score: 0.7374\n",
      "Fold 7 Epoch 91/100, Loss: 2.0111, Val Loss: 2.0259, F1 Score: 0.7389\n",
      "Fold 7 Epoch 92/100, Loss: 2.0099, Val Loss: 2.0238, F1 Score: 0.7383\n",
      "Fold 7 Epoch 93/100, Loss: 2.0100, Val Loss: 2.0199, F1 Score: 0.7351\n",
      "Fold 7 Epoch 94/100, Loss: 2.0040, Val Loss: 2.0088, F1 Score: 0.8014\n",
      "Fold 7 Epoch 95/100, Loss: 1.9955, Val Loss: 1.9942, F1 Score: 0.8088\n",
      "Fold 7 Epoch 96/100, Loss: 1.9875, Val Loss: 1.9877, F1 Score: 0.8088\n",
      "Fold 7 Epoch 97/100, Loss: 1.9803, Val Loss: 1.9838, F1 Score: 0.8094\n",
      "Fold 7 Epoch 98/100, Loss: 1.9773, Val Loss: 1.9818, F1 Score: 0.8088\n",
      "Fold 7 Epoch 99/100, Loss: 1.9755, Val Loss: 1.9813, F1 Score: 0.8083\n",
      "Fold 7 Epoch 100/100, Loss: 1.9741, Val Loss: 1.9799, F1 Score: 0.8088\n",
      "Starting Fold 8\n",
      "Fold 8 Epoch 1/100, Loss: 2.7056, Val Loss: 2.6990, F1 Score: 0.2268\n",
      "Fold 8 Epoch 2/100, Loss: 2.6903, Val Loss: 2.6788, F1 Score: 0.2076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 Epoch 3/100, Loss: 2.6577, Val Loss: 2.6194, F1 Score: 0.2076\n",
      "Fold 8 Epoch 4/100, Loss: 2.4810, Val Loss: 2.3571, F1 Score: 0.2076\n",
      "Fold 8 Epoch 5/100, Loss: 2.3146, Val Loss: 2.1913, F1 Score: 0.5750\n",
      "Fold 8 Epoch 6/100, Loss: 2.1630, Val Loss: 2.1362, F1 Score: 0.5747\n",
      "Fold 8 Epoch 7/100, Loss: 2.1450, Val Loss: 2.1344, F1 Score: 0.5747\n",
      "Fold 8 Epoch 8/100, Loss: 2.1411, Val Loss: 2.1343, F1 Score: 0.5601\n",
      "Fold 8 Epoch 9/100, Loss: 2.1416, Val Loss: 2.1341, F1 Score: 0.5576\n",
      "Fold 8 Epoch 10/100, Loss: 2.1399, Val Loss: 2.1346, F1 Score: 0.5574\n",
      "Fold 8 Epoch 11/100, Loss: 2.1406, Val Loss: 2.1339, F1 Score: 0.5596\n",
      "Fold 8 Epoch 12/100, Loss: 2.1385, Val Loss: 2.1338, F1 Score: 0.5567\n",
      "Fold 8 Epoch 13/100, Loss: 2.1377, Val Loss: 2.1330, F1 Score: 0.5573\n",
      "Fold 8 Epoch 14/100, Loss: 2.1384, Val Loss: 2.1324, F1 Score: 0.5574\n",
      "Fold 8 Epoch 15/100, Loss: 2.1369, Val Loss: 2.1311, F1 Score: 0.5574\n",
      "Fold 8 Epoch 16/100, Loss: 2.1362, Val Loss: 2.1303, F1 Score: 0.5575\n",
      "Fold 8 Epoch 17/100, Loss: 2.1358, Val Loss: 2.1291, F1 Score: 0.5594\n",
      "Fold 8 Epoch 18/100, Loss: 2.1333, Val Loss: 2.1275, F1 Score: 0.5569\n",
      "Fold 8 Epoch 19/100, Loss: 2.1339, Val Loss: 2.1256, F1 Score: 0.5570\n",
      "Fold 8 Epoch 20/100, Loss: 2.1339, Val Loss: 2.1235, F1 Score: 0.5578\n",
      "Fold 8 Epoch 21/100, Loss: 2.1289, Val Loss: 2.1215, F1 Score: 0.5561\n",
      "Fold 8 Epoch 22/100, Loss: 2.1265, Val Loss: 2.1189, F1 Score: 0.5562\n",
      "Fold 8 Epoch 23/100, Loss: 2.1240, Val Loss: 2.1158, F1 Score: 0.5643\n",
      "Fold 8 Epoch 24/100, Loss: 2.1216, Val Loss: 2.1122, F1 Score: 0.5645\n",
      "Fold 8 Epoch 25/100, Loss: 2.1165, Val Loss: 2.1074, F1 Score: 0.5652\n",
      "Fold 8 Epoch 26/100, Loss: 2.1131, Val Loss: 2.1008, F1 Score: 0.6344\n",
      "Fold 8 Epoch 27/100, Loss: 2.1044, Val Loss: 2.0907, F1 Score: 0.6843\n",
      "Fold 8 Epoch 28/100, Loss: 2.0957, Val Loss: 2.0804, F1 Score: 0.6853\n",
      "Fold 8 Epoch 29/100, Loss: 2.0864, Val Loss: 2.0726, F1 Score: 0.6853\n",
      "Fold 8 Epoch 30/100, Loss: 2.0790, Val Loss: 2.0680, F1 Score: 0.6843\n",
      "Fold 8 Epoch 31/100, Loss: 2.0733, Val Loss: 2.0643, F1 Score: 0.6791\n",
      "Fold 8 Epoch 32/100, Loss: 2.0710, Val Loss: 2.0607, F1 Score: 0.6776\n",
      "Fold 8 Epoch 33/100, Loss: 2.0662, Val Loss: 2.0566, F1 Score: 0.7331\n",
      "Fold 8 Epoch 34/100, Loss: 2.0591, Val Loss: 2.0519, F1 Score: 0.7321\n",
      "Fold 8 Epoch 35/100, Loss: 2.0535, Val Loss: 2.0470, F1 Score: 0.7305\n",
      "Fold 8 Epoch 36/100, Loss: 2.0488, Val Loss: 2.0402, F1 Score: 0.7324\n",
      "Fold 8 Epoch 37/100, Loss: 2.0426, Val Loss: 2.0360, F1 Score: 0.7330\n",
      "Fold 8 Epoch 38/100, Loss: 2.0359, Val Loss: 2.0312, F1 Score: 0.7331\n",
      "Fold 8 Epoch 39/100, Loss: 2.0309, Val Loss: 2.0289, F1 Score: 0.7370\n",
      "Fold 8 Epoch 40/100, Loss: 2.0286, Val Loss: 2.0250, F1 Score: 0.7365\n",
      "Fold 8 Epoch 41/100, Loss: 2.0276, Val Loss: 2.0214, F1 Score: 0.7521\n",
      "Fold 8 Epoch 42/100, Loss: 2.0226, Val Loss: 2.0188, F1 Score: 0.7515\n",
      "Fold 8 Epoch 43/100, Loss: 2.0198, Val Loss: 2.0172, F1 Score: 0.7504\n",
      "Fold 8 Epoch 44/100, Loss: 2.0178, Val Loss: 2.0141, F1 Score: 0.7513\n",
      "Fold 8 Epoch 45/100, Loss: 2.0145, Val Loss: 2.0111, F1 Score: 0.7545\n",
      "Fold 8 Epoch 46/100, Loss: 2.0098, Val Loss: 2.0056, F1 Score: 0.8039\n",
      "Fold 8 Epoch 47/100, Loss: 2.0024, Val Loss: 1.9971, F1 Score: 0.8045\n",
      "Fold 8 Epoch 48/100, Loss: 1.9934, Val Loss: 1.9896, F1 Score: 0.8047\n",
      "Fold 8 Epoch 49/100, Loss: 1.9869, Val Loss: 1.9847, F1 Score: 0.8060\n",
      "Fold 8 Epoch 50/100, Loss: 1.9820, Val Loss: 1.9828, F1 Score: 0.8073\n",
      "Fold 8 Epoch 51/100, Loss: 1.9808, Val Loss: 1.9816, F1 Score: 0.8073\n",
      "Fold 8 Epoch 52/100, Loss: 1.9790, Val Loss: 1.9806, F1 Score: 0.8069\n",
      "Fold 8 Epoch 53/100, Loss: 1.9766, Val Loss: 1.9801, F1 Score: 0.8073\n",
      "Fold 8 Epoch 54/100, Loss: 1.9775, Val Loss: 1.9799, F1 Score: 0.8073\n",
      "Fold 8 Epoch 55/100, Loss: 1.9765, Val Loss: 1.9798, F1 Score: 0.8069\n",
      "Fold 8 Epoch 56/100, Loss: 1.9741, Val Loss: 1.9794, F1 Score: 0.8067\n",
      "Fold 8 Epoch 57/100, Loss: 1.9745, Val Loss: 1.9792, F1 Score: 0.8079\n",
      "Fold 8 Epoch 58/100, Loss: 1.9745, Val Loss: 1.9792, F1 Score: 0.8068\n",
      "Fold 8 Epoch 59/100, Loss: 1.9733, Val Loss: 1.9791, F1 Score: 0.8067\n",
      "Fold 8 Epoch 60/100, Loss: 1.9742, Val Loss: 1.9791, F1 Score: 0.8070\n",
      "Fold 8 Epoch 61/100, Loss: 1.9728, Val Loss: 1.9788, F1 Score: 0.8077\n",
      "Fold 8 Epoch 62/100, Loss: 1.9735, Val Loss: 1.9786, F1 Score: 0.8079\n",
      "Fold 8 Epoch 63/100, Loss: 1.9718, Val Loss: 1.9785, F1 Score: 0.8079\n",
      "Fold 8 Epoch 64/100, Loss: 1.9715, Val Loss: 1.9786, F1 Score: 0.8079\n",
      "Fold 8 Epoch 65/100, Loss: 1.9719, Val Loss: 1.9788, F1 Score: 0.8079\n",
      "Fold 8 Epoch 66/100, Loss: 1.9724, Val Loss: 1.9788, F1 Score: 0.8079\n",
      "Fold 8 Epoch 67/100, Loss: 1.9717, Val Loss: 1.9786, F1 Score: 0.8079\n",
      "Fold 8 Epoch 68/100, Loss: 1.9724, Val Loss: 1.9786, F1 Score: 0.8079\n",
      "Fold 8 Epoch 69/100, Loss: 1.9711, Val Loss: 1.9788, F1 Score: 0.8073\n",
      "Fold 8 Epoch 70/100, Loss: 1.9709, Val Loss: 1.9786, F1 Score: 0.8079\n",
      "Fold 8 Epoch 71/100, Loss: 1.9713, Val Loss: 1.9785, F1 Score: 0.8079\n",
      "Fold 8 Epoch 72/100, Loss: 1.9712, Val Loss: 1.9785, F1 Score: 0.8079\n",
      "Fold 8 Epoch 73/100, Loss: 1.9715, Val Loss: 1.9783, F1 Score: 0.8079\n",
      "Fold 8 Epoch 74/100, Loss: 1.9717, Val Loss: 1.9785, F1 Score: 0.8079\n",
      "Fold 8 Epoch 75/100, Loss: 1.9706, Val Loss: 1.9783, F1 Score: 0.8081\n",
      "Fold 8 Epoch 76/100, Loss: 1.9706, Val Loss: 1.9782, F1 Score: 0.8092\n",
      "Fold 8 Epoch 77/100, Loss: 1.9724, Val Loss: 1.9782, F1 Score: 0.8081\n",
      "Fold 8 Epoch 78/100, Loss: 1.9702, Val Loss: 1.9783, F1 Score: 0.8081\n",
      "Fold 8 Epoch 79/100, Loss: 1.9711, Val Loss: 1.9783, F1 Score: 0.8079\n",
      "Fold 8 Epoch 80/100, Loss: 1.9709, Val Loss: 1.9781, F1 Score: 0.8079\n",
      "Fold 8 Epoch 81/100, Loss: 1.9707, Val Loss: 1.9781, F1 Score: 0.8079\n",
      "Fold 8 Epoch 82/100, Loss: 1.9703, Val Loss: 1.9780, F1 Score: 0.8079\n",
      "Fold 8 Epoch 83/100, Loss: 1.9715, Val Loss: 1.9780, F1 Score: 0.8079\n",
      "Fold 8 Epoch 84/100, Loss: 1.9713, Val Loss: 1.9782, F1 Score: 0.8079\n",
      "Fold 8 Epoch 85/100, Loss: 1.9704, Val Loss: 1.9779, F1 Score: 0.8092\n",
      "Fold 8 Epoch 86/100, Loss: 1.9702, Val Loss: 1.9780, F1 Score: 0.8092\n",
      "Fold 8 Epoch 87/100, Loss: 1.9703, Val Loss: 1.9778, F1 Score: 0.8092\n",
      "Fold 8 Epoch 88/100, Loss: 1.9696, Val Loss: 1.9777, F1 Score: 0.8092\n",
      "Fold 8 Epoch 89/100, Loss: 1.9707, Val Loss: 1.9776, F1 Score: 0.8092\n",
      "Fold 8 Epoch 90/100, Loss: 1.9715, Val Loss: 1.9776, F1 Score: 0.8092\n",
      "Fold 8 Epoch 91/100, Loss: 1.9705, Val Loss: 1.9776, F1 Score: 0.8092\n",
      "Fold 8 Epoch 92/100, Loss: 1.9695, Val Loss: 1.9773, F1 Score: 0.8092\n",
      "Fold 8 Epoch 93/100, Loss: 1.9698, Val Loss: 1.9770, F1 Score: 0.8092\n",
      "Fold 8 Epoch 94/100, Loss: 1.9694, Val Loss: 1.9768, F1 Score: 0.8092\n",
      "Fold 8 Epoch 95/100, Loss: 1.9702, Val Loss: 1.9765, F1 Score: 0.8092\n",
      "Fold 8 Epoch 96/100, Loss: 1.9692, Val Loss: 1.9763, F1 Score: 0.8092\n",
      "Fold 8 Epoch 97/100, Loss: 1.9681, Val Loss: 1.9759, F1 Score: 0.8082\n",
      "Fold 8 Epoch 98/100, Loss: 1.9684, Val Loss: 1.9757, F1 Score: 0.8082\n",
      "Fold 8 Epoch 99/100, Loss: 1.9685, Val Loss: 1.9753, F1 Score: 0.8090\n",
      "Fold 8 Epoch 100/100, Loss: 1.9678, Val Loss: 1.9748, F1 Score: 0.8092\n",
      "Starting Fold 9\n",
      "Fold 9 Epoch 1/100, Loss: 2.7019, Val Loss: 2.6940, F1 Score: 0.2081\n",
      "Fold 9 Epoch 2/100, Loss: 2.6826, Val Loss: 2.6661, F1 Score: 0.2081\n",
      "Fold 9 Epoch 3/100, Loss: 2.6138, Val Loss: 2.4496, F1 Score: 0.2081\n",
      "Fold 9 Epoch 4/100, Loss: 2.3832, Val Loss: 2.3159, F1 Score: 0.2081\n",
      "Fold 9 Epoch 5/100, Loss: 2.2344, Val Loss: 2.1407, F1 Score: 0.5742\n",
      "Fold 9 Epoch 6/100, Loss: 2.1483, Val Loss: 2.1340, F1 Score: 0.5743\n",
      "Fold 9 Epoch 7/100, Loss: 2.1436, Val Loss: 2.1322, F1 Score: 0.5649\n",
      "Fold 9 Epoch 8/100, Loss: 2.1416, Val Loss: 2.1313, F1 Score: 0.5639\n",
      "Fold 9 Epoch 9/100, Loss: 2.1417, Val Loss: 2.1309, F1 Score: 0.5550\n",
      "Fold 9 Epoch 10/100, Loss: 2.1416, Val Loss: 2.1304, F1 Score: 0.5547\n",
      "Fold 9 Epoch 11/100, Loss: 2.1384, Val Loss: 2.1300, F1 Score: 0.5549\n",
      "Fold 9 Epoch 12/100, Loss: 2.1400, Val Loss: 2.1294, F1 Score: 0.5569\n",
      "Fold 9 Epoch 13/100, Loss: 2.1374, Val Loss: 2.1286, F1 Score: 0.5538\n",
      "Fold 9 Epoch 14/100, Loss: 2.1400, Val Loss: 2.1278, F1 Score: 0.5535\n",
      "Fold 9 Epoch 15/100, Loss: 2.1370, Val Loss: 2.1266, F1 Score: 0.5557\n",
      "Fold 9 Epoch 16/100, Loss: 2.1369, Val Loss: 2.1252, F1 Score: 0.5537\n",
      "Fold 9 Epoch 17/100, Loss: 2.1344, Val Loss: 2.1235, F1 Score: 0.5533\n",
      "Fold 9 Epoch 18/100, Loss: 2.1366, Val Loss: 2.1215, F1 Score: 0.5536\n",
      "Fold 9 Epoch 19/100, Loss: 2.1342, Val Loss: 2.1197, F1 Score: 0.5537\n",
      "Fold 9 Epoch 20/100, Loss: 2.1306, Val Loss: 2.1173, F1 Score: 0.5535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 Epoch 21/100, Loss: 2.1293, Val Loss: 2.1147, F1 Score: 0.5558\n",
      "Fold 9 Epoch 22/100, Loss: 2.1270, Val Loss: 2.1113, F1 Score: 0.5571\n",
      "Fold 9 Epoch 23/100, Loss: 2.1236, Val Loss: 2.1074, F1 Score: 0.5672\n",
      "Fold 9 Epoch 24/100, Loss: 2.1210, Val Loss: 2.1027, F1 Score: 0.5754\n",
      "Fold 9 Epoch 25/100, Loss: 2.1187, Val Loss: 2.0971, F1 Score: 0.5754\n",
      "Fold 9 Epoch 26/100, Loss: 2.1106, Val Loss: 2.0911, F1 Score: 0.6232\n",
      "Fold 9 Epoch 27/100, Loss: 2.1054, Val Loss: 2.0849, F1 Score: 0.6681\n",
      "Fold 9 Epoch 28/100, Loss: 2.0989, Val Loss: 2.0731, F1 Score: 0.6921\n",
      "Fold 9 Epoch 29/100, Loss: 2.0884, Val Loss: 2.0599, F1 Score: 0.6931\n",
      "Fold 9 Epoch 30/100, Loss: 2.0762, Val Loss: 2.0455, F1 Score: 0.7652\n",
      "Fold 9 Epoch 31/100, Loss: 2.0642, Val Loss: 2.0342, F1 Score: 0.7645\n",
      "Fold 9 Epoch 32/100, Loss: 2.0553, Val Loss: 2.0228, F1 Score: 0.7607\n",
      "Fold 9 Epoch 33/100, Loss: 2.0470, Val Loss: 2.0140, F1 Score: 0.7616\n",
      "Fold 9 Epoch 34/100, Loss: 2.0386, Val Loss: 2.0081, F1 Score: 0.7636\n",
      "Fold 9 Epoch 35/100, Loss: 2.0345, Val Loss: 2.0047, F1 Score: 0.7654\n",
      "Fold 9 Epoch 36/100, Loss: 2.0316, Val Loss: 2.0018, F1 Score: 0.7638\n",
      "Fold 9 Epoch 37/100, Loss: 2.0259, Val Loss: 1.9986, F1 Score: 0.7662\n",
      "Fold 9 Epoch 38/100, Loss: 2.0247, Val Loss: 1.9955, F1 Score: 0.7653\n",
      "Fold 9 Epoch 39/100, Loss: 2.0201, Val Loss: 1.9924, F1 Score: 0.7695\n",
      "Fold 9 Epoch 40/100, Loss: 2.0171, Val Loss: 1.9891, F1 Score: 0.7706\n",
      "Fold 9 Epoch 41/100, Loss: 2.0136, Val Loss: 1.9863, F1 Score: 0.7950\n",
      "Fold 9 Epoch 42/100, Loss: 2.0111, Val Loss: 1.9830, F1 Score: 0.8247\n",
      "Fold 9 Epoch 43/100, Loss: 2.0089, Val Loss: 1.9804, F1 Score: 0.8287\n",
      "Fold 9 Epoch 44/100, Loss: 2.0031, Val Loss: 1.9773, F1 Score: 0.8287\n",
      "Fold 9 Epoch 45/100, Loss: 2.0033, Val Loss: 1.9741, F1 Score: 0.8298\n",
      "Fold 9 Epoch 46/100, Loss: 1.9990, Val Loss: 1.9709, F1 Score: 0.8298\n",
      "Fold 9 Epoch 47/100, Loss: 1.9960, Val Loss: 1.9682, F1 Score: 0.8298\n",
      "Fold 9 Epoch 48/100, Loss: 1.9952, Val Loss: 1.9653, F1 Score: 0.8258\n",
      "Fold 9 Epoch 49/100, Loss: 1.9903, Val Loss: 1.9625, F1 Score: 0.8236\n",
      "Fold 9 Epoch 50/100, Loss: 1.9883, Val Loss: 1.9598, F1 Score: 0.8235\n",
      "Fold 9 Epoch 51/100, Loss: 1.9852, Val Loss: 1.9579, F1 Score: 0.8236\n",
      "Fold 9 Epoch 52/100, Loss: 1.9834, Val Loss: 1.9563, F1 Score: 0.8235\n",
      "Fold 9 Epoch 53/100, Loss: 1.9840, Val Loss: 1.9557, F1 Score: 0.8236\n",
      "Fold 9 Epoch 54/100, Loss: 1.9804, Val Loss: 1.9542, F1 Score: 0.8236\n",
      "Fold 9 Epoch 55/100, Loss: 1.9795, Val Loss: 1.9533, F1 Score: 0.8235\n",
      "Fold 9 Epoch 56/100, Loss: 1.9793, Val Loss: 1.9531, F1 Score: 0.8235\n",
      "Fold 9 Epoch 57/100, Loss: 1.9792, Val Loss: 1.9526, F1 Score: 0.8235\n",
      "Fold 9 Epoch 58/100, Loss: 1.9779, Val Loss: 1.9525, F1 Score: 0.8235\n",
      "Fold 9 Epoch 59/100, Loss: 1.9769, Val Loss: 1.9519, F1 Score: 0.8235\n",
      "Fold 9 Epoch 60/100, Loss: 1.9789, Val Loss: 1.9519, F1 Score: 0.8247\n",
      "Fold 9 Epoch 61/100, Loss: 1.9761, Val Loss: 1.9513, F1 Score: 0.8247\n",
      "Fold 9 Epoch 62/100, Loss: 1.9757, Val Loss: 1.9514, F1 Score: 0.8247\n",
      "Fold 9 Epoch 63/100, Loss: 1.9744, Val Loss: 1.9512, F1 Score: 0.8247\n",
      "Fold 9 Epoch 64/100, Loss: 1.9779, Val Loss: 1.9514, F1 Score: 0.8248\n",
      "Fold 9 Epoch 65/100, Loss: 1.9737, Val Loss: 1.9512, F1 Score: 0.8247\n",
      "Fold 9 Epoch 66/100, Loss: 1.9743, Val Loss: 1.9509, F1 Score: 0.8247\n",
      "Fold 9 Epoch 67/100, Loss: 1.9752, Val Loss: 1.9506, F1 Score: 0.8261\n",
      "Fold 9 Epoch 68/100, Loss: 1.9744, Val Loss: 1.9510, F1 Score: 0.8247\n",
      "Fold 9 Epoch 69/100, Loss: 1.9743, Val Loss: 1.9510, F1 Score: 0.8247\n",
      "Fold 9 Epoch 70/100, Loss: 1.9738, Val Loss: 1.9508, F1 Score: 0.8247\n",
      "Fold 9 Epoch 71/100, Loss: 1.9738, Val Loss: 1.9509, F1 Score: 0.8247\n",
      "Fold 9 Epoch 72/100, Loss: 1.9727, Val Loss: 1.9508, F1 Score: 0.8247\n",
      "Fold 9 Epoch 73/100, Loss: 1.9735, Val Loss: 1.9511, F1 Score: 0.8248\n",
      "Fold 9 Epoch 74/100, Loss: 1.9733, Val Loss: 1.9504, F1 Score: 0.8261\n",
      "Fold 9 Epoch 75/100, Loss: 1.9725, Val Loss: 1.9507, F1 Score: 0.8247\n",
      "Fold 9 Epoch 76/100, Loss: 1.9734, Val Loss: 1.9508, F1 Score: 0.8247\n",
      "Fold 9 Epoch 77/100, Loss: 1.9747, Val Loss: 1.9503, F1 Score: 0.8265\n",
      "Fold 9 Epoch 78/100, Loss: 1.9743, Val Loss: 1.9510, F1 Score: 0.8249\n",
      "Fold 9 Epoch 79/100, Loss: 1.9738, Val Loss: 1.9509, F1 Score: 0.8262\n",
      "Fold 9 Epoch 80/100, Loss: 1.9741, Val Loss: 1.9507, F1 Score: 0.8261\n",
      "Fold 9 Epoch 81/100, Loss: 1.9733, Val Loss: 1.9504, F1 Score: 0.8249\n",
      "Fold 9 Epoch 82/100, Loss: 1.9730, Val Loss: 1.9504, F1 Score: 0.8249\n",
      "Fold 9 Epoch 83/100, Loss: 1.9735, Val Loss: 1.9503, F1 Score: 0.8265\n",
      "Fold 9 Epoch 84/100, Loss: 1.9731, Val Loss: 1.9506, F1 Score: 0.8248\n",
      "Fold 9 Epoch 85/100, Loss: 1.9728, Val Loss: 1.9507, F1 Score: 0.8262\n",
      "Fold 9 Epoch 86/100, Loss: 1.9734, Val Loss: 1.9503, F1 Score: 0.8263\n",
      "Fold 9 Epoch 87/100, Loss: 1.9725, Val Loss: 1.9506, F1 Score: 0.8262\n",
      "Fold 9 Epoch 88/100, Loss: 1.9732, Val Loss: 1.9501, F1 Score: 0.8265\n",
      "Fold 9 Epoch 89/100, Loss: 1.9721, Val Loss: 1.9504, F1 Score: 0.8263\n",
      "Fold 9 Epoch 90/100, Loss: 1.9729, Val Loss: 1.9501, F1 Score: 0.8265\n",
      "Fold 9 Epoch 91/100, Loss: 1.9728, Val Loss: 1.9500, F1 Score: 0.8272\n",
      "Fold 9 Epoch 92/100, Loss: 1.9718, Val Loss: 1.9502, F1 Score: 0.8265\n",
      "Fold 9 Epoch 93/100, Loss: 1.9722, Val Loss: 1.9501, F1 Score: 0.8287\n",
      "Fold 9 Epoch 94/100, Loss: 1.9733, Val Loss: 1.9503, F1 Score: 0.8263\n",
      "Fold 9 Epoch 95/100, Loss: 1.9718, Val Loss: 1.9505, F1 Score: 0.8262\n",
      "Fold 9 Epoch 96/100, Loss: 1.9732, Val Loss: 1.9503, F1 Score: 0.8263\n",
      "Fold 9 Epoch 97/100, Loss: 1.9725, Val Loss: 1.9505, F1 Score: 0.8263\n",
      "Fold 9 Epoch 98/100, Loss: 1.9719, Val Loss: 1.9500, F1 Score: 0.8275\n",
      "Fold 9 Epoch 99/100, Loss: 1.9726, Val Loss: 1.9504, F1 Score: 0.8263\n",
      "Fold 9 Epoch 100/100, Loss: 1.9732, Val Loss: 1.9500, F1 Score: 0.8265\n",
      "Starting Fold 10\n",
      "Fold 10 Epoch 1/100, Loss: 2.7004, Val Loss: 2.6921, F1 Score: 0.2068\n",
      "Fold 10 Epoch 2/100, Loss: 2.6810, Val Loss: 2.6645, F1 Score: 0.2068\n",
      "Fold 10 Epoch 3/100, Loss: 2.6245, Val Loss: 2.5082, F1 Score: 0.2068\n",
      "Fold 10 Epoch 4/100, Loss: 2.4101, Val Loss: 2.3459, F1 Score: 0.2068\n",
      "Fold 10 Epoch 5/100, Loss: 2.2852, Val Loss: 2.1565, F1 Score: 0.5711\n",
      "Fold 10 Epoch 6/100, Loss: 2.1535, Val Loss: 2.1388, F1 Score: 0.5692\n",
      "Fold 10 Epoch 7/100, Loss: 2.1449, Val Loss: 2.1367, F1 Score: 0.5692\n",
      "Fold 10 Epoch 8/100, Loss: 2.1432, Val Loss: 2.1335, F1 Score: 0.5671\n",
      "Fold 10 Epoch 9/100, Loss: 2.1414, Val Loss: 2.1327, F1 Score: 0.5684\n",
      "Fold 10 Epoch 10/100, Loss: 2.1405, Val Loss: 2.1321, F1 Score: 0.5597\n",
      "Fold 10 Epoch 11/100, Loss: 2.1384, Val Loss: 2.1327, F1 Score: 0.5674\n",
      "Fold 10 Epoch 12/100, Loss: 2.1380, Val Loss: 2.1315, F1 Score: 0.5589\n",
      "Fold 10 Epoch 13/100, Loss: 2.1369, Val Loss: 2.1308, F1 Score: 0.5561\n",
      "Fold 10 Epoch 14/100, Loss: 2.1360, Val Loss: 2.1305, F1 Score: 0.5575\n",
      "Fold 10 Epoch 15/100, Loss: 2.1368, Val Loss: 2.1298, F1 Score: 0.5563\n",
      "Fold 10 Epoch 16/100, Loss: 2.1342, Val Loss: 2.1285, F1 Score: 0.5563\n",
      "Fold 10 Epoch 17/100, Loss: 2.1334, Val Loss: 2.1274, F1 Score: 0.5570\n",
      "Fold 10 Epoch 18/100, Loss: 2.1332, Val Loss: 2.1258, F1 Score: 0.5532\n",
      "Fold 10 Epoch 19/100, Loss: 2.1308, Val Loss: 2.1242, F1 Score: 0.5561\n",
      "Fold 10 Epoch 20/100, Loss: 2.1290, Val Loss: 2.1222, F1 Score: 0.5547\n",
      "Fold 10 Epoch 21/100, Loss: 2.1272, Val Loss: 2.1203, F1 Score: 0.5546\n",
      "Fold 10 Epoch 22/100, Loss: 2.1263, Val Loss: 2.1179, F1 Score: 0.5583\n",
      "Fold 10 Epoch 23/100, Loss: 2.1223, Val Loss: 2.1150, F1 Score: 0.5619\n",
      "Fold 10 Epoch 24/100, Loss: 2.1197, Val Loss: 2.1114, F1 Score: 0.5656\n",
      "Fold 10 Epoch 25/100, Loss: 2.1163, Val Loss: 2.1072, F1 Score: 0.5720\n",
      "Fold 10 Epoch 26/100, Loss: 2.1118, Val Loss: 2.1007, F1 Score: 0.6449\n",
      "Fold 10 Epoch 27/100, Loss: 2.1046, Val Loss: 2.0901, F1 Score: 0.6852\n",
      "Fold 10 Epoch 28/100, Loss: 2.0928, Val Loss: 2.0772, F1 Score: 0.6852\n",
      "Fold 10 Epoch 29/100, Loss: 2.0825, Val Loss: 2.0713, F1 Score: 0.6852\n",
      "Fold 10 Epoch 30/100, Loss: 2.0764, Val Loss: 2.0656, F1 Score: 0.6852\n",
      "Fold 10 Epoch 31/100, Loss: 2.0723, Val Loss: 2.0601, F1 Score: 0.7510\n",
      "Fold 10 Epoch 32/100, Loss: 2.0679, Val Loss: 2.0542, F1 Score: 0.7499\n",
      "Fold 10 Epoch 33/100, Loss: 2.0597, Val Loss: 2.0471, F1 Score: 0.7441\n",
      "Fold 10 Epoch 34/100, Loss: 2.0545, Val Loss: 2.0399, F1 Score: 0.7437\n",
      "Fold 10 Epoch 35/100, Loss: 2.0475, Val Loss: 2.0349, F1 Score: 0.7441\n",
      "Fold 10 Epoch 36/100, Loss: 2.0390, Val Loss: 2.0253, F1 Score: 0.7582\n",
      "Fold 10 Epoch 37/100, Loss: 2.0337, Val Loss: 2.0206, F1 Score: 0.7546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 Epoch 38/100, Loss: 2.0290, Val Loss: 2.0172, F1 Score: 0.7546\n",
      "Fold 10 Epoch 39/100, Loss: 2.0247, Val Loss: 2.0146, F1 Score: 0.7535\n",
      "Fold 10 Epoch 40/100, Loss: 2.0195, Val Loss: 2.0123, F1 Score: 0.7540\n",
      "Fold 10 Epoch 41/100, Loss: 2.0170, Val Loss: 2.0105, F1 Score: 0.7528\n",
      "Fold 10 Epoch 42/100, Loss: 2.0154, Val Loss: 2.0080, F1 Score: 0.7527\n",
      "Fold 10 Epoch 43/100, Loss: 2.0120, Val Loss: 2.0055, F1 Score: 0.7780\n",
      "Fold 10 Epoch 44/100, Loss: 2.0104, Val Loss: 2.0027, F1 Score: 0.7934\n",
      "Fold 10 Epoch 45/100, Loss: 2.0046, Val Loss: 1.9978, F1 Score: 0.8115\n",
      "Fold 10 Epoch 46/100, Loss: 1.9989, Val Loss: 1.9925, F1 Score: 0.8128\n",
      "Fold 10 Epoch 47/100, Loss: 1.9950, Val Loss: 1.9878, F1 Score: 0.8128\n",
      "Fold 10 Epoch 48/100, Loss: 1.9904, Val Loss: 1.9843, F1 Score: 0.8128\n",
      "Fold 10 Epoch 49/100, Loss: 1.9862, Val Loss: 1.9816, F1 Score: 0.8141\n",
      "Fold 10 Epoch 50/100, Loss: 1.9828, Val Loss: 1.9793, F1 Score: 0.8141\n",
      "Fold 10 Epoch 51/100, Loss: 1.9808, Val Loss: 1.9783, F1 Score: 0.8139\n",
      "Fold 10 Epoch 52/100, Loss: 1.9789, Val Loss: 1.9777, F1 Score: 0.8139\n",
      "Fold 10 Epoch 53/100, Loss: 1.9761, Val Loss: 1.9768, F1 Score: 0.8139\n",
      "Fold 10 Epoch 54/100, Loss: 1.9754, Val Loss: 1.9760, F1 Score: 0.8139\n",
      "Fold 10 Epoch 55/100, Loss: 1.9746, Val Loss: 1.9753, F1 Score: 0.8139\n",
      "Fold 10 Epoch 56/100, Loss: 1.9725, Val Loss: 1.9742, F1 Score: 0.8139\n",
      "Fold 10 Epoch 57/100, Loss: 1.9717, Val Loss: 1.9731, F1 Score: 0.8138\n",
      "Fold 10 Epoch 58/100, Loss: 1.9705, Val Loss: 1.9713, F1 Score: 0.8134\n",
      "Fold 10 Epoch 59/100, Loss: 1.9703, Val Loss: 1.9695, F1 Score: 0.8134\n",
      "Fold 10 Epoch 60/100, Loss: 1.9665, Val Loss: 1.9657, F1 Score: 0.8504\n",
      "Fold 10 Epoch 61/100, Loss: 1.9621, Val Loss: 1.9614, F1 Score: 0.8504\n",
      "Fold 10 Epoch 62/100, Loss: 1.9591, Val Loss: 1.9573, F1 Score: 0.8529\n",
      "Fold 10 Epoch 63/100, Loss: 1.9570, Val Loss: 1.9549, F1 Score: 0.8529\n",
      "Fold 10 Epoch 64/100, Loss: 1.9524, Val Loss: 1.9533, F1 Score: 0.8531\n",
      "Fold 10 Epoch 65/100, Loss: 1.9513, Val Loss: 1.9529, F1 Score: 0.8531\n",
      "Fold 10 Epoch 66/100, Loss: 1.9501, Val Loss: 1.9522, F1 Score: 0.8531\n",
      "Fold 10 Epoch 67/100, Loss: 1.9497, Val Loss: 1.9517, F1 Score: 0.8543\n",
      "Fold 10 Epoch 68/100, Loss: 1.9484, Val Loss: 1.9517, F1 Score: 0.8543\n",
      "Fold 10 Epoch 69/100, Loss: 1.9472, Val Loss: 1.9512, F1 Score: 0.8543\n",
      "Fold 10 Epoch 70/100, Loss: 1.9475, Val Loss: 1.9513, F1 Score: 0.8543\n",
      "Fold 10 Epoch 71/100, Loss: 1.9472, Val Loss: 1.9510, F1 Score: 0.8543\n",
      "Fold 10 Epoch 72/100, Loss: 1.9458, Val Loss: 1.9511, F1 Score: 0.8543\n",
      "Fold 10 Epoch 73/100, Loss: 1.9448, Val Loss: 1.9510, F1 Score: 0.8543\n",
      "Fold 10 Epoch 74/100, Loss: 1.9449, Val Loss: 1.9511, F1 Score: 0.8543\n",
      "Fold 10 Epoch 75/100, Loss: 1.9455, Val Loss: 1.9512, F1 Score: 0.8543\n",
      "Fold 10 Epoch 76/100, Loss: 1.9458, Val Loss: 1.9510, F1 Score: 0.8543\n",
      "Fold 10 Epoch 77/100, Loss: 1.9442, Val Loss: 1.9510, F1 Score: 0.8543\n",
      "Fold 10 Epoch 78/100, Loss: 1.9454, Val Loss: 1.9509, F1 Score: 0.8543\n",
      "Fold 10 Epoch 79/100, Loss: 1.9441, Val Loss: 1.9508, F1 Score: 0.8543\n",
      "Fold 10 Epoch 80/100, Loss: 1.9438, Val Loss: 1.9505, F1 Score: 0.8543\n",
      "Fold 10 Epoch 81/100, Loss: 1.9445, Val Loss: 1.9505, F1 Score: 0.8543\n",
      "Fold 10 Epoch 82/100, Loss: 1.9430, Val Loss: 1.9503, F1 Score: 0.8543\n",
      "Fold 10 Epoch 83/100, Loss: 1.9447, Val Loss: 1.9505, F1 Score: 0.8543\n",
      "Fold 10 Epoch 84/100, Loss: 1.9434, Val Loss: 1.9506, F1 Score: 0.8543\n",
      "Fold 10 Epoch 85/100, Loss: 1.9426, Val Loss: 1.9505, F1 Score: 0.8543\n",
      "Fold 10 Epoch 86/100, Loss: 1.9436, Val Loss: 1.9505, F1 Score: 0.8543\n",
      "Fold 10 Epoch 87/100, Loss: 1.9426, Val Loss: 1.9505, F1 Score: 0.8543\n",
      "Fold 10 Epoch 88/100, Loss: 1.9427, Val Loss: 1.9503, F1 Score: 0.8539\n",
      "Fold 10 Epoch 89/100, Loss: 1.9438, Val Loss: 1.9502, F1 Score: 0.8531\n",
      "Fold 10 Epoch 90/100, Loss: 1.9427, Val Loss: 1.9504, F1 Score: 0.8526\n",
      "Fold 10 Epoch 91/100, Loss: 1.9430, Val Loss: 1.9505, F1 Score: 0.8539\n",
      "Fold 10 Epoch 92/100, Loss: 1.9419, Val Loss: 1.9502, F1 Score: 0.8539\n",
      "Fold 10 Epoch 93/100, Loss: 1.9436, Val Loss: 1.9501, F1 Score: 0.8539\n",
      "Fold 10 Epoch 94/100, Loss: 1.9440, Val Loss: 1.9502, F1 Score: 0.8526\n",
      "Fold 10 Epoch 95/100, Loss: 1.9420, Val Loss: 1.9497, F1 Score: 0.8539\n",
      "Fold 10 Epoch 96/100, Loss: 1.9432, Val Loss: 1.9499, F1 Score: 0.8528\n",
      "Fold 10 Epoch 97/100, Loss: 1.9414, Val Loss: 1.9499, F1 Score: 0.8543\n",
      "Fold 10 Epoch 98/100, Loss: 1.9431, Val Loss: 1.9498, F1 Score: 0.8543\n",
      "Fold 10 Epoch 99/100, Loss: 1.9435, Val Loss: 1.9495, F1 Score: 0.8543\n",
      "Fold 10 Epoch 100/100, Loss: 1.9435, Val Loss: 1.9494, F1 Score: 0.8553\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "best_model = None\n",
    "best_f1_score = 0  # Track the best F1 score\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train_tensor, y_train_tensor)):\n",
    "    print(f\"Starting Fold {fold + 1}\")\n",
    "    \n",
    "    # Split data into train and validation sets for this fold\n",
    "    X_fold_train, X_fold_val = X_train_tensor[train_index], X_train_tensor[val_index]\n",
    "    y_fold_train, y_fold_val = y_train_tensor[train_index], y_train_tensor[val_index]\n",
    "    \n",
    "    # Move data to the specified device\n",
    "    X_fold_train = X_fold_train.to(device)\n",
    "    X_fold_val = X_fold_val.to(device)\n",
    "    y_fold_train = y_fold_train.to(device)\n",
    "    y_fold_val = y_fold_val.to(device)\n",
    "    \n",
    "    # Create DataLoaders for this fold\n",
    "    train_dataset = TensorDataset(X_fold_train, y_fold_train)\n",
    "    val_dataset = TensorDataset(X_fold_val, y_fold_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = DeepARGMLP(input_dim=X_train.shape[1], output_dim=num_classes).to(device)  # Move model to device\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    # Train the model for each fold with 100 epochs\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move batch to device\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Evaluate on the fold validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)  # Move batch to device\n",
    "                outputs = model(X_val_batch)\n",
    "                loss = criterion(outputs, y_val_batch)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                all_predictions.extend(predicted.cpu().numpy())  # Move to CPU for metric calculation\n",
    "                all_labels.extend(y_val_batch.cpu().numpy())\n",
    "        \n",
    "        # Calculate F1 score for this epoch\n",
    "        fold_f1_score = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        print(f\"Fold {fold + 1} Epoch {epoch + 1}/{epochs}, \"\n",
    "              f\"Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "              f\"F1 Score: {fold_f1_score:.4f}\")\n",
    "    \n",
    "    # Save the best model based on F1 score\n",
    "    if fold_f1_score > best_f1_score:\n",
    "        best_f1_score = fold_f1_score\n",
    "        best_model = model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a601535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.871900826446281\n",
      "Recall: 0.871900826446281\n",
      "F1 Score: 0.871900826446281\n",
      "Macro Precision: 0.5643069086989727\n",
      "Macro Recall: 0.5746196221833307\n",
      "Macro F1 Score: 0.5680843386734744\n",
      "Weighted Precision: 0.8411475747732174\n",
      "Weighted Recall: 0.871900826446281\n",
      "Weighted F1 Score: 0.8550724492499289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_val_batch, y_val_batch in val_loader:\n",
    "        outputs = best_model(X_val_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_val_batch.cpu().numpy())\n",
    "\n",
    "# Calculate macro precision, recall, and F1 score, as well as per-class metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    all_labels, all_predictions, average=None, labels=range(num_classes)\n",
    ")\n",
    "\n",
    "avg_precision, avg_recall, avg_f1, avg_support = precision_recall_fscore_support(\n",
    "    all_labels, all_predictions, average='micro'\n",
    ")\n",
    "\n",
    "# Calculate macro-averaged metrics (ignoring class imbalance)\n",
    "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "    all_labels, all_predictions, average='macro'\n",
    ")\n",
    "\n",
    "weighted_precision, weighted_recall, weighted_f1, weighted_support = precision_recall_fscore_support(\n",
    "    all_labels, all_predictions, average='weighted'\n",
    ")\n",
    "\n",
    "# Print macro-averaged metrics\n",
    "print(f\"Precision: {avg_precision}\")\n",
    "print(f\"Recall: {avg_recall}\")\n",
    "print(f\"F1 Score: {avg_f1}\")\n",
    "\n",
    "print(f\"Macro Precision: {macro_precision}\")\n",
    "print(f\"Macro Recall: {macro_recall}\")\n",
    "print(f\"Macro F1 Score: {macro_f1}\")\n",
    "\n",
    "print(f\"Weighted Precision: {weighted_precision}\")\n",
    "print(f\"Weighted Recall: {weighted_recall}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6de2bf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'aminoglycoside': Precision: 0.85, Recall: 0.85, F1 Score: 0.85, Support: 40\n",
      "Class 'bacitracin': Precision: 0.8657718120805369, Recall: 0.9416058394160584, F1 Score: 0.9020979020979021, Support: 274\n",
      "Class 'beta_lactam': Precision: 0.925, Recall: 0.925, F1 Score: 0.925, Support: 240\n",
      "Class 'chloramphenicol': Precision: 0.8076923076923077, Recall: 0.7777777777777778, F1 Score: 0.7924528301886792, Support: 27\n",
      "Class 'fosfomycin': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 16\n",
      "Class 'fosmidomycin': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 0\n",
      "Class 'glycopeptide': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 1\n",
      "Class 'macrolide-lincosamide-streptogramin': Precision: 0.7246376811594203, Recall: 0.8771929824561403, F1 Score: 0.7936507936507936, Support: 57\n",
      "Class 'multidrug': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 11\n",
      "Class 'mupirocin': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 0\n",
      "Class 'polymyxin': Precision: 0.9056603773584906, Recall: 0.8, F1 Score: 0.8495575221238938, Support: 60\n",
      "Class 'quinolone': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 0\n",
      "Class 'sulfonamide': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 0\n",
      "Class 'tetracycline': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 0\n",
      "Class 'trimethoprim': Precision: 0.0, Recall: 0.0, F1 Score: 0.0, Support: 0\n"
     ]
    }
   ],
   "source": [
    "class_names = label_encoder.classes_\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"Class '{class_name}': Precision: {precision[i]}, Recall: {recall[i]}, F1 Score: {f1[i]}, Support: {support[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e38cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/best_dna_lr_model.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/best_dna_lr_model.pth\"\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "426c2b9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9c3632f1078b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX_test_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ace246d3b150>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "output_path = \"results/lr_dna_model_predictions.csv\"\n",
    "\n",
    "# After evaluating the best model on the holdout set and collecting predictions\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_test_batch, y_test_batch in test_loader:\n",
    "        outputs = best_model(X_test_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_test_batch.cpu().numpy())\n",
    "\n",
    "# Decode labels and predictions to their original class names\n",
    "true_labels = label_encoder.inverse_transform(all_labels)\n",
    "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
    "\n",
    "# Include the ID (index) from y_val\n",
    "ids = range(len(y_test))  # Assuming y_val is the original holdout labels array\n",
    "print(len(y_test))\n",
    "print(len(all_labels))\n",
    "print(len(all_predictions))\n",
    "\n",
    "# Create a DataFrame to store the outputs\n",
    "outputs_df = pd.DataFrame({\n",
    "    \"ID\": ids,\n",
    "    \"True Label\": true_labels,\n",
    "    \"Predicted Label\": predicted_labels\n",
    "})\n",
    "\n",
    "# Save the outputs to a CSV file\n",
    "outputs_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65b4ae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3115\n",
      "3115\n",
      "3115\n",
      "Predictions saved to results/lr_dna_model_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "output_path = \"results/lr_dna_model_predictions.csv\"\n",
    "\n",
    "# After evaluating the best model on the holdout set and collecting predictions\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_test_batch, y_test_batch in test_loader:\n",
    "        # Move input batch and labels to the same device as the model\n",
    "        X_test_batch = X_test_batch.to(device)\n",
    "        y_test_batch = y_test_batch.to(device)\n",
    "        \n",
    "        outputs = best_model(X_test_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Move predictions and labels to CPU for saving\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_test_batch.cpu().numpy())\n",
    "\n",
    "# Decode labels and predictions to their original class names\n",
    "true_labels = label_encoder.inverse_transform(all_labels)\n",
    "predicted_labels = label_encoder.inverse_transform(all_predictions)\n",
    "\n",
    "# Include the ID (index) from y_test\n",
    "ids = range(len(y_test))\n",
    "\n",
    "# Create a DataFrame to store the outputs\n",
    "outputs_df = pd.DataFrame({\n",
    "    \"ID\": ids,\n",
    "    \"True Label\": true_labels,\n",
    "    \"Predicted Label\": predicted_labels\n",
    "})\n",
    "\n",
    "# Save the outputs to a CSV file\n",
    "outputs_df.to_csv(output_path, index=False)\n",
    "print(f\"Predictions saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4ab88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
